
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="记录一些关于数学、计算机的知识，以及一些日常。">
      
      
      
        <link rel="canonical" href="https://yfy.cqu.ai/%E5%AD%A6%E4%B9%A0/2023/04/16/2023-04-16-CUDA%E7%BC%96%E7%A8%8B%26%E5%B7%A5%E5%85%B7/">
      
      
        <link rel="prev" href="../2023-04-16-CUDA%E6%9E%B6%E6%9E%84/">
      
      
        <link rel="next" href="../2023-04-16-CUDA%E4%BC%98%E5%8C%96/">
      
      
      <link rel="icon" href="../../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.3">
    
    
      
        <title>CUDA编程&工具 - Rain的随笔</title>
      
    
    
      <link rel="stylesheet" href="../../../../../assets/stylesheets/main.50c56a3b.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#参考资料" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../../../.." title="Rain的随笔" class="md-header__button md-logo" aria-label="Rain的随笔" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Rain的随笔
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              CUDA编程&工具
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    
  
  
    <li class="md-tabs__item md-tabs__item--active">
      <a href="../../../../.." class="md-tabs__link">
        
  
    
  
  博客

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../about/" class="md-tabs__link">
        
  
    
  
  关于

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../tags/" class="md-tabs__link">
        
  
    
  
  标签

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../series/" class="md-tabs__link">
        
  
    
  
  系列

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../tools/" class="md-tabs__link">
        
  
    
  
  工具

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../../archive/2024/" class="md-tabs__link">
          
  
  归档

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../../category/homelab/" class="md-tabs__link">
          
  
  分类

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
                
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" hidden>
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../../.." title="Rain的随笔" class="md-nav__button md-logo" aria-label="Rain的随笔" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Rain的随笔
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
    
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      <a href="../../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    博客
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../about/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    关于
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../tags/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    标签
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../series/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    系列
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../tools/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    工具
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="">
            
  
  <span class="md-ellipsis">
    归档
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            归档
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../../archive/2024/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2024
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../../archive/2023/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2023
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../../archive/2022/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2022
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../../archive/2021/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2021
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../../archive/2020/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2020
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../../archive/2019/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2019
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="">
            
  
  <span class="md-ellipsis">
    分类
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            分类
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../../category/homelab/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    homelab
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../../category/%E4%B8%AA%E4%BA%BA/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    个人
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../../category/%E5%8D%9A%E5%AE%A2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    博客
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../../category/%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E7%BD%91%E7%BB%9C%E8%87%AA%E7%94%B1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何实现网络自由
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../../category/%E5%AD%A6%E4%B9%A0/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../../category/%E5%B7%A5%E5%85%B7/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    工具
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../../category/%E6%8A%98%E8%85%BE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    折腾
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../../category/%E6%9D%82%E6%96%87/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    杂文
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../../category/%E7%BC%96%E7%A8%8B/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    编程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../../category/%E8%99%9A%E6%8B%9F%E5%8C%96/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    虚拟化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../../category/%E8%AE%BE%E5%A4%87/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    设备
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../../category/%E8%AF%BE%E7%A8%8B/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    课程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../../category/%E9%98%85%E8%AF%BB/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    阅读
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
  <div class="md-content md-content--post" data-md-component="content">
    <div class="md-sidebar md-sidebar--post" data-md-component="sidebar" data-md-type="navigation">
      <div class="md-sidebar__scrollwrap">
        <div class="md-sidebar__inner md-post">
          <nav class="md-nav md-nav--primary">
            <div class="md-post__back">
              <div class="md-nav__title md-nav__container">
                <a href="../../../../.." class="md-nav__link">
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
                  <span class="md-ellipsis">
                    回到主页
                  </span>
                </a>
              </div>
            </div>
            
            <ul class="md-post__meta md-nav__list">
              <li class="md-nav__item md-nav__item--section">
                <div class="md-post__title">
                  <span class="md-ellipsis">
                    元数据
                  </span>
                </div>
                <nav class="md-nav">
                  <ul class="md-nav__list">
                    <li class="md-nav__item">
                      <div class="md-nav__link">
                        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 19H5V8h14m-3-7v2H8V1H6v2H5c-1.11 0-2 .89-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2h-1V1m-1 11h-5v5h5v-5Z"/></svg>
                        <time datetime="2023-04-16 16:13:00" class="md-ellipsis">2023年4月16日</time>
                      </div>
                    </li>
                    
                    
                      <li class="md-nav__item">
                        <div class="md-nav__link">
                          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9 3v15h3V3H9m3 2 4 13 3-1-4-13-3 1M5 5v13h3V5H5M3 19v2h18v-2H3Z"/></svg>
                          <span class="md-ellipsis">
                            分类于
                            
                              <a href="../../../../../category/%E5%AD%A6%E4%B9%A0/">学习</a></span>
                        </div>
                      </li>
                    
                    
                      
                      <li class="md-nav__item">
                        <div class="md-nav__link">
                          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 20a8 8 0 0 0 8-8 8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8m0-18a10 10 0 0 1 10 10 10 10 0 0 1-10 10C6.47 22 2 17.5 2 12A10 10 0 0 1 12 2m.5 5v5.25l4.5 2.67-.75 1.23L11 13V7h1.5Z"/></svg>
                          <span class="md-ellipsis">
                            
                              需要 23 分钟阅读时间
                            
                          </span>
                        </div>
                      </li>
                    
                  </ul>
                </nav>
              </li>
            </ul>
          </nav>
          
            

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#参考资料" class="md-nav__link">
    <span class="md-ellipsis">
      参考资料
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cuda安装" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA安装
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CUDA安装">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#有用链接" class="md-nav__link">
    <span class="md-ellipsis">
      有用链接
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#依赖" class="md-nav__link">
    <span class="md-ellipsis">
      依赖
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#两种方式" class="md-nav__link">
    <span class="md-ellipsis">
      两种方式
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#不同版本冲突性" class="md-nav__link">
    <span class="md-ellipsis">
      不同版本冲突性
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#卸载" class="md-nav__link">
    <span class="md-ellipsis">
      卸载
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#环境变量选择版本" class="md-nav__link">
    <span class="md-ellipsis">
      环境变量选择版本
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#实例" class="md-nav__link">
    <span class="md-ellipsis">
      实例
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#nvcc" class="md-nav__link">
    <span class="md-ellipsis">
      NVCC
    </span>
  </a>
  
    <nav class="md-nav" aria-label="NVCC">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#两阶段编译" class="md-nav__link">
    <span class="md-ellipsis">
      两阶段编译
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#jit机制" class="md-nav__link">
    <span class="md-ellipsis">
      JIT机制
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fatbinaries" class="md-nav__link">
    <span class="md-ellipsis">
      fatbinaries
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example" class="md-nav__link">
    <span class="md-ellipsis">
      example
    </span>
  </a>
  
    <nav class="md-nav" aria-label="example">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#jit" class="md-nav__link">
    <span class="md-ellipsis">
      JIT
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#省略gpu-code" class="md-nav__link">
    <span class="md-ellipsis">
      省略gpu-code
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#同时省略arch-gpu-code" class="md-nav__link">
    <span class="md-ellipsis">
      同时省略arch, gpu-code
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#-generate-code指定多种组合" class="md-nav__link">
    <span class="md-ellipsis">
      -generate-code指定多种组合
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nvcc选项" class="md-nav__link">
    <span class="md-ellipsis">
      nvcc选项
    </span>
  </a>
  
    <nav class="md-nav" aria-label="nvcc选项">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#环境变量" class="md-nav__link">
    <span class="md-ellipsis">
      环境变量
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cuda编程" class="md-nav__link">
    <span class="md-ellipsis">
      Cuda编程
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Cuda编程">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#统一内存模型" class="md-nav__link">
    <span class="md-ellipsis">
      统一内存模型
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#同步" class="md-nav__link">
    <span class="md-ellipsis">
      同步
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cublas" class="md-nav__link">
    <span class="md-ellipsis">
      cuBLAS
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#工具" class="md-nav__link">
    <span class="md-ellipsis">
      工具
    </span>
  </a>
  
    <nav class="md-nav" aria-label="工具">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#nvprof" class="md-nav__link">
    <span class="md-ellipsis">
      nvprof
    </span>
  </a>
  
    <nav class="md-nav" aria-label="nvprof">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#visual-profilernvvp" class="md-nav__link">
    <span class="md-ellipsis">
      Visual Profiler/nvvp
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Visual Profiler/nvvp">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#java版本" class="md-nav__link">
    <span class="md-ellipsis">
      java版本
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ioexception-locking-file" class="md-nav__link">
    <span class="md-ellipsis">
      IOException: locking file
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pc-sample-view" class="md-nav__link">
    <span class="md-ellipsis">
      PC sample View
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#memory统计" class="md-nav__link">
    <span class="md-ellipsis">
      memory统计
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#source-disassembly" class="md-nav__link">
    <span class="md-ellipsis">
      source-disassembly
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#warp-statestall原因" class="md-nav__link">
    <span class="md-ellipsis">
      Warp state/stall原因
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nvprof_1" class="md-nav__link">
    <span class="md-ellipsis">
      nvprof
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nsight-compute" class="md-nav__link">
    <span class="md-ellipsis">
      Nsight Compute
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Nsight Compute">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ncu" class="md-nav__link">
    <span class="md-ellipsis">
      ncu
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ncu">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#metric" class="md-nav__link">
    <span class="md-ellipsis">
      metric
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#问题" class="md-nav__link">
    <span class="md-ellipsis">
      问题
    </span>
  </a>
  
    <nav class="md-nav" aria-label="问题">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#profiling-is-not-supported-on-this-device" class="md-nav__link">
    <span class="md-ellipsis">
      Profiling is not supported on this device
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#无权限使用metric" class="md-nav__link">
    <span class="md-ellipsis">
      无权限使用metric
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#调试工具" class="md-nav__link">
    <span class="md-ellipsis">
      调试工具
    </span>
  </a>
  
    <nav class="md-nav" aria-label="调试工具">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cuda-memck" class="md-nav__link">
    <span class="md-ellipsis">
      cuda-memck
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-gdb调试" class="md-nav__link">
    <span class="md-ellipsis">
      cuda-gdb调试
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nvbit" class="md-nav__link">
    <span class="md-ellipsis">
      NVbit
    </span>
  </a>
  
    <nav class="md-nav" aria-label="NVbit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#warp-level指令" class="md-nav__link">
    <span class="md-ellipsis">
      warp-level指令
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-sdk" class="md-nav__link">
    <span class="md-ellipsis">
      cuda SDK
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
          
        </div>
      </div>
    </div>
    <article class="md-content__inner md-typeset">
      
        
  
  

<nav class="md-tags" >
  
    
    
    
      <a href="../../../../../tags/#cuda" class="md-tag">cuda</a>
    
  
</nav>



<h2 id="参考资料">参考资料<a class="headerlink" href="#参考资料" title="Permanent link">&para;</a></h2>
<ul>
<li><a href="https://cuda-tutorial.readthedocs.io/en/latest/tutorials/tutorial01/">Tutorial 01: Say Hello to CUDA - CUDA Tutorial (cuda-tutorial.readthedocs.io)</a></li>
<li><a href="https://hpc.pku.edu.cn/download_2_cuda.html">北京大学高性能计算平台 (pku.edu.cn)</a></li>
</ul>
<h2 id="cuda安装">CUDA安装<a class="headerlink" href="#cuda安装" title="Permanent link">&para;</a></h2>
<p>总结：
- <strong>最简单方式是看cuda下载页面提供的安装命令</strong>
- deb安装貌似无法只安装cuda，不安装驱动
- runfile安装可以做到不重启
- cuda-toolkit-12-1包含cuda
- nvidia-driver-530包含驱动</p>
<!-- more -->

<h3 id="有用链接">有用链接<a class="headerlink" href="#有用链接" title="Permanent link">&para;</a></h3>
<ul>
<li>官方文档：<a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/">cuda-installation-guide-linux 12.1 documentation (nvidia.com)</a></li>
</ul>
<p>cuda下载
- 最新版：<a href="https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;Distribution=Ubuntu&amp;target_version=20.04">CUDA Toolkit 12.1 Downloads | NVIDIA Developer</a>
- 历史版：<a href="https://developer.nvidia.com/cuda-toolkit-archive">CUDA Toolkit Archive | NVIDIA Developer</a></p>
<h3 id="依赖">依赖<a class="headerlink" href="#依赖" title="Permanent link">&para;</a></h3>
<p><em>ps: 需要管理员权限</em></p>
<ul>
<li>nvidia gpu &amp; gpu driver</li>
<li>gcc</li>
<li>kernel header
<div class="language-text highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>sudo apt install linux-headers-$(uname -r)
</span></code></pre></div><blockquote>
<p>The CUDA Driver requires that the kernel headers and development packages for the running version of the kernel be installed at the time of the driver installation, as well whenever the driver is rebuilt.</p>
</blockquote>
</li>
<li>禁用noveau驱动，安装cuda时也会自动安装nvidia驱动</li>
</ul>
<h3 id="两种方式">两种方式<a class="headerlink" href="#两种方式" title="Permanent link">&para;</a></h3>
<ul>
<li>rpm/deb packages</li>
<li>runfile package</li>
<li>和发行版无关(distribution-independent package)</li>
</ul>
<p>安装deb后，是添加了一个repo。还需要再手动install cuda。
<strong>不知为何安装cuda时一定会自动更新driver，而使用runfile方式，则可以选择不安装驱动。</strong></p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>fyyuan@snode6 ➜  archive dpkg --list |grep cuda-repo
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>ii  cuda-repo-ubuntu2004-11-5-local                             11.5.2-495.29.05-1                                             amd64        cuda repository configuration files
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>ii  cuda-repo-ubuntu2004-12-1-local                             12.1.0-530.30.02-1                                             amd64        cuda repository configuration files
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>fyyuan@snode6 ➜  archive sudo apt install cuda --no-install-recommends
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>Reading package lists... Done
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>Building dependency tree
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>Reading state information... Done
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a>The following packages were automatically installed and are no longer required:
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>  cuda-11-5 cuda-cccl-11-5 cuda-command-line-tools-11-5 cuda-compiler-11-5 cuda-cudart-11-5 cuda-cudart-dev-11-5 cuda-cuobjdump-11-5 cuda-cupti-11-5 cuda-cupti-dev-11-5 cuda-cuxxfilt-11-5 cuda-demo-suite-11-5 cuda-documentation-11-5 cuda-driver-dev-11-5 cuda-gdb-11-5
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a>  cuda-libraries-11-5 cuda-libraries-dev-11-5 cuda-memcheck-11-5 cuda-nsight-11-5 cuda-nsight-compute-11-5 cuda-nsight-systems-11-5 cuda-nvcc-11-5 cuda-nvdisasm-11-5 cuda-nvml-dev-11-5 cuda-nvprof-11-5 cuda-nvprune-11-5 cuda-nvrtc-11-5 cuda-nvrtc-dev-11-5 cuda-nvtx-11-5
</span><span id="__span-2-8"><a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a>  cuda-nvvp-11-5 cuda-runtime-11-5 cuda-samples-11-5 cuda-sanitizer-11-5 cuda-toolkit-11-5 cuda-toolkit-11-5-config-common cuda-toolkit-11-config-common cuda-tools-11-5 cuda-visual-tools-11-5 gds-tools-11-5 libcublas-11-5 libcublas-dev-11-5 libcufft-11-5 libcufft-dev-11-5
</span><span id="__span-2-9"><a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a>  libcufile-11-5 libcufile-dev-11-5 libcurand-11-5 libcurand-dev-11-5 libcusolver-11-5 libcusolver-dev-11-5 libcusparse-11-5 libcusparse-dev-11-5 libnpp-11-5 libnpp-dev-11-5 libnvidia-common-495 libnvjpeg-11-5 libnvjpeg-dev-11-5 nsight-compute-2021.3.1 nsight-systems-2021.3.3
</span><span id="__span-2-10"><a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a>Use &#39;sudo apt autoremove&#39; to remove them.
</span><span id="__span-2-11"><a id="__codelineno-2-11" name="__codelineno-2-11" href="#__codelineno-2-11"></a>The following additional packages will be installed:
</span><span id="__span-2-12"><a id="__codelineno-2-12" name="__codelineno-2-12" href="#__codelineno-2-12"></a>  cuda-12-1 cuda-cccl-12-1 cuda-command-line-tools-12-1 cuda-compiler-12-1 cuda-cudart-12-1 cuda-cudart-dev-12-1 cuda-cuobjdump-12-1 cuda-cupti-12-1 cuda-cupti-dev-12-1 cuda-cuxxfilt-12-1 cuda-demo-suite-12-1 cuda-documentation-12-1 cuda-driver-dev-12-1 cuda-drivers
</span><span id="__span-2-13"><a id="__codelineno-2-13" name="__codelineno-2-13" href="#__codelineno-2-13"></a>  cuda-drivers-530 cuda-gdb-12-1 cuda-libraries-12-1 cuda-libraries-dev-12-1 cuda-nsight-12-1 cuda-nsight-compute-12-1 cuda-nsight-systems-12-1 cuda-nvcc-12-1 cuda-nvdisasm-12-1 cuda-nvml-dev-12-1 cuda-nvprof-12-1 cuda-nvprune-12-1 cuda-nvrtc-12-1 cuda-nvrtc-dev-12-1
</span><span id="__span-2-14"><a id="__codelineno-2-14" name="__codelineno-2-14" href="#__codelineno-2-14"></a>  cuda-nvtx-12-1 cuda-nvvp-12-1 cuda-opencl-12-1 cuda-opencl-dev-12-1 cuda-profiler-api-12-1 cuda-runtime-12-1 cuda-sanitizer-12-1 cuda-toolkit-12-1 cuda-toolkit-12-1-config-common cuda-toolkit-12-config-common cuda-tools-12-1 cuda-visual-tools-12-1 gds-tools-12-1 libcublas-12-1
</span><span id="__span-2-15"><a id="__codelineno-2-15" name="__codelineno-2-15" href="#__codelineno-2-15"></a>  libcublas-dev-12-1 libcufft-12-1 libcufft-dev-12-1 libcufile-12-1 libcufile-dev-12-1 libcurand-12-1 libcurand-dev-12-1 libcusolver-12-1 libcusolver-dev-12-1 libcusparse-12-1 libcusparse-dev-12-1 libnpp-12-1 libnpp-dev-12-1 libnvidia-cfg1-530 libnvidia-common-530
</span><span id="__span-2-16"><a id="__codelineno-2-16" name="__codelineno-2-16" href="#__codelineno-2-16"></a>  libnvidia-compute-530 libnvidia-decode-530 libnvidia-encode-530 libnvidia-extra-530 libnvidia-fbc1-530 libnvidia-gl-530 libnvjitlink-12-1 libnvjitlink-dev-12-1 libnvjpeg-12-1 libnvjpeg-dev-12-1 libnvvm-samples-12-1 nsight-compute-2023.1.0 nsight-systems-2023.1.2
</span><span id="__span-2-17"><a id="__codelineno-2-17" name="__codelineno-2-17" href="#__codelineno-2-17"></a>  nvidia-compute-utils-530 nvidia-dkms-530 nvidia-driver-530 nvidia-kernel-common-530 nvidia-kernel-source-530 nvidia-modprobe nvidia-settings nvidia-utils-530 xserver-xorg-video-nvidia-530
</span><span id="__span-2-18"><a id="__codelineno-2-18" name="__codelineno-2-18" href="#__codelineno-2-18"></a>Recommended packages:
</span><span id="__span-2-19"><a id="__codelineno-2-19" name="__codelineno-2-19" href="#__codelineno-2-19"></a>  libnvidia-compute-530:i386 libnvidia-decode-530:i386 libnvidia-encode-530:i386 libnvidia-fbc1-530:i386 libnvidia-gl-530:i386
</span><span id="__span-2-20"><a id="__codelineno-2-20" name="__codelineno-2-20" href="#__codelineno-2-20"></a>The following packages will be REMOVED:
</span><span id="__span-2-21"><a id="__codelineno-2-21" name="__codelineno-2-21" href="#__codelineno-2-21"></a>  cuda-drivers-495 libnvidia-cfg1-495 libnvidia-compute-495 libnvidia-decode-495 libnvidia-encode-495 libnvidia-extra-495 libnvidia-fbc1-495 libnvidia-gl-495 nvidia-compute-utils-495 nvidia-dkms-495 nvidia-driver-495 nvidia-kernel-common-495 nvidia-kernel-source-495
</span><span id="__span-2-22"><a id="__codelineno-2-22" name="__codelineno-2-22" href="#__codelineno-2-22"></a>  nvidia-utils-495 xserver-xorg-video-nvidia-495
</span><span id="__span-2-23"><a id="__codelineno-2-23" name="__codelineno-2-23" href="#__codelineno-2-23"></a>The following NEW packages will be installed:
</span><span id="__span-2-24"><a id="__codelineno-2-24" name="__codelineno-2-24" href="#__codelineno-2-24"></a>  cuda-12-1 cuda-cccl-12-1 cuda-command-line-tools-12-1 cuda-compiler-12-1 cuda-cudart-12-1 cuda-cudart-dev-12-1 cuda-cuobjdump-12-1 cuda-cupti-12-1 cuda-cupti-dev-12-1 cuda-cuxxfilt-12-1 cuda-demo-suite-12-1 cuda-documentation-12-1 cuda-driver-dev-12-1 cuda-drivers-530
</span><span id="__span-2-25"><a id="__codelineno-2-25" name="__codelineno-2-25" href="#__codelineno-2-25"></a>  cuda-gdb-12-1 cuda-libraries-12-1 cuda-libraries-dev-12-1 cuda-nsight-12-1 cuda-nsight-compute-12-1 cuda-nsight-systems-12-1 cuda-nvcc-12-1 cuda-nvdisasm-12-1 cuda-nvml-dev-12-1 cuda-nvprof-12-1 cuda-nvprune-12-1 cuda-nvrtc-12-1 cuda-nvrtc-dev-12-1 cuda-nvtx-12-1 cuda-nvvp-12-1
</span><span id="__span-2-26"><a id="__codelineno-2-26" name="__codelineno-2-26" href="#__codelineno-2-26"></a>  cuda-opencl-12-1 cuda-opencl-dev-12-1 cuda-profiler-api-12-1 cuda-runtime-12-1 cuda-sanitizer-12-1 cuda-toolkit-12-1 cuda-toolkit-12-1-config-common cuda-toolkit-12-config-common cuda-tools-12-1 cuda-visual-tools-12-1 gds-tools-12-1 libcublas-12-1 libcublas-dev-12-1
</span><span id="__span-2-27"><a id="__codelineno-2-27" name="__codelineno-2-27" href="#__codelineno-2-27"></a>  libcufft-12-1 libcufft-dev-12-1 libcufile-12-1 libcufile-dev-12-1 libcurand-12-1 libcurand-dev-12-1 libcusolver-12-1 libcusolver-dev-12-1 libcusparse-12-1 libcusparse-dev-12-1 libnpp-12-1 libnpp-dev-12-1 libnvidia-cfg1-530 libnvidia-common-530 libnvidia-compute-530
</span><span id="__span-2-28"><a id="__codelineno-2-28" name="__codelineno-2-28" href="#__codelineno-2-28"></a>  libnvidia-decode-530 libnvidia-encode-530 libnvidia-extra-530 libnvidia-fbc1-530 libnvidia-gl-530 libnvjitlink-12-1 libnvjitlink-dev-12-1 libnvjpeg-12-1 libnvjpeg-dev-12-1 libnvvm-samples-12-1 nsight-compute-2023.1.0 nsight-systems-2023.1.2 nvidia-compute-utils-530
</span><span id="__span-2-29"><a id="__codelineno-2-29" name="__codelineno-2-29" href="#__codelineno-2-29"></a>  nvidia-dkms-530 nvidia-driver-530 nvidia-kernel-common-530 nvidia-kernel-source-530 nvidia-utils-530 xserver-xorg-video-nvidia-530
</span><span id="__span-2-30"><a id="__codelineno-2-30" name="__codelineno-2-30" href="#__codelineno-2-30"></a>The following packages will be upgraded:
</span><span id="__span-2-31"><a id="__codelineno-2-31" name="__codelineno-2-31" href="#__codelineno-2-31"></a>  cuda cuda-drivers nvidia-modprobe nvidia-settings
</span><span id="__span-2-32"><a id="__codelineno-2-32" name="__codelineno-2-32" href="#__codelineno-2-32"></a>4 upgraded, 76 newly installed, 15 to remove and 21 not upgraded.
</span><span id="__span-2-33"><a id="__codelineno-2-33" name="__codelineno-2-33" href="#__codelineno-2-33"></a>Need to get 0 B/3,012 MB of archives.
</span><span id="__span-2-34"><a id="__codelineno-2-34" name="__codelineno-2-34" href="#__codelineno-2-34"></a>After this operation, 7,064 MB of additional disk space will be used.
</span><span id="__span-2-35"><a id="__codelineno-2-35" name="__codelineno-2-35" href="#__codelineno-2-35"></a>Do you want to continue? [Y/n]
</span></code></pre></div>
<p>只安装cuda
<div class="language-text highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>fyyuan@snode6 ➜  archive sudo sh cuda_11.3.0_465.19.01_linux.run --toolkit
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>===========
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>= Summary =
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>===========
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>Driver:   Not Selected
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>Toolkit:  Installed in /usr/local/cuda-11.3/
</span><span id="__span-3-8"><a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a>Samples:  Installed in /usr/local/cuda-11.3/
</span><span id="__span-3-9"><a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a>
</span><span id="__span-3-10"><a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>Please make sure that
</span><span id="__span-3-11"><a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a> -   PATH includes /usr/local/cuda-11.3/bin
</span><span id="__span-3-12"><a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a> -   LD_LIBRARY_PATH includes /usr/local/cuda-11.3/lib64, or, add /usr/local/cuda-11.3/lib64 to /etc/ld.so.conf and run ldconfig as root
</span><span id="__span-3-13"><a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a>
</span><span id="__span-3-14"><a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a>To uninstall the CUDA Toolkit, run cuda-uninstaller in /usr/local/cuda-11.3/bin
</span><span id="__span-3-15"><a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a>***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 465.00 is required for CUDA 11.3 functionality to work.
</span><span id="__span-3-16"><a id="__codelineno-3-16" name="__codelineno-3-16" href="#__codelineno-3-16"></a>To install the driver using this installer, run the following command, replacing &lt;CudaInstaller&gt; with the name of this run file:
</span><span id="__span-3-17"><a id="__codelineno-3-17" name="__codelineno-3-17" href="#__codelineno-3-17"></a>    sudo &lt;CudaInstaller&gt;.run --silent --driver
</span><span id="__span-3-18"><a id="__codelineno-3-18" name="__codelineno-3-18" href="#__codelineno-3-18"></a>
</span><span id="__span-3-19"><a id="__codelineno-3-19" name="__codelineno-3-19" href="#__codelineno-3-19"></a>Logfile is /var/log/cuda-installer.log
</span></code></pre></div></p>
<h3 id="不同版本冲突性">不同版本冲突性<a class="headerlink" href="#不同版本冲突性" title="Permanent link">&para;</a></h3>
<p>https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#handle-conflicting-installation-methods
总结：
- 安装cuda tookit，不同版本间没有冲突
- 安装driver，不同版本使用同一种方式(deb或runfile)安装没有冲突</p>
<h3 id="卸载">卸载<a class="headerlink" href="#卸载" title="Permanent link">&para;</a></h3>
<div class="language-text highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>sudo /usr/local/cuda-X.Y/bin/cuda-uninstaller  # runfile
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a>
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a># cuda
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>sudo apt-get --purge remove &quot;*cuda*&quot; &quot;*cublas*&quot; &quot;*cufft*&quot; &quot;*cufile*&quot; &quot;*curand*&quot; \
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a> &quot;*cusolver*&quot; &quot;*cusparse*&quot; &quot;*gds-tools*&quot; &quot;*npp*&quot; &quot;*nvjpeg*&quot; &quot;nsight*&quot; &quot;*nvvm*&quot;
</span><span id="__span-4-7"><a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a>
</span><span id="__span-4-8"><a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a># driver
</span><span id="__span-4-9"><a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a>sudo apt purge &quot;*nvidia*&quot; &quot;libxnvctrl*&quot;   # 只卸载nvidia-driver-xxx不够
</span><span id="__span-4-10"><a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a>
</span><span id="__span-4-11"><a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a>sudo apt autoremove
</span></code></pre></div>
<h3 id="环境变量选择版本">环境变量选择版本<a class="headerlink" href="#环境变量选择版本" title="Permanent link">&para;</a></h3>
<div class="language-text highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>cuda_version=&quot;cuda-11.0&quot;
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>export PATH=&quot;/usr/local/$cuda_version/bin:$PATH&quot;
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>export LD_LIBRARY_PATH=&quot;/usr/local/$cuda_version/lib64:$LD_LIBRARY_PATH&quot;
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>export demo_suite=&quot;/usr/local/$cuda_version/extras/demo_suite&quot;
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a>cd $demo_suite
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>./deviceQuery   # 获得设备信息
</span></code></pre></div>
<p>nvcc使用
<div class="language-bash highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>nvcc<span class="w"> </span>-std<span class="o">=</span>c++11<span class="w"> </span>-lcurand<span class="w"> </span>-lcublas
</span></code></pre></div></p>
<h3 id="实例">实例<a class="headerlink" href="#实例" title="Permanent link">&para;</a></h3>
<p>卸载runfile后重启（没重启还有很多nvdia的模块）
<div class="language-text highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>root@icarus3:/home/nfs/fyyuan# lsmod |grep nv
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a>nvidia_drm             65536  0
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>nvidia_modeset       1273856  1 nvidia_drm
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a>nvidia              55701504  27 gdrdrv,nvidia_modeset
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>drm_kms_helper        184320  4 ast,nvidia_drm
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a>drm                   495616  7 drm_kms_helper,drm_vram_helper,ast,nvidia,nvidia_drm,ttm
</span></code></pre></div></p>
<p>安装driver
<div class="language-text highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a>root@icarus3:/home/nfs/fyyuan# apt-cache policy nvidia-driver-530
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a>nvidia-driver-530:
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a>  Installed: 530.41.03-0ubuntu0.20.04.2
</span><span id="__span-8-4"><a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a>  Candidate: 530.41.03-0ubuntu0.20.04.2
</span><span id="__span-8-5"><a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a>  Version table:
</span><span id="__span-8-6"><a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a> *** 530.41.03-0ubuntu0.20.04.2 500
</span><span id="__span-8-7"><a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a>        500 https://mirrors.ustc.edu.cn/ubuntu focal-updates/restricted amd64 Packages
</span><span id="__span-8-8"><a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>        500 https://mirrors.ustc.edu.cn/ubuntu focal-security/restricted amd64 Packages
</span><span id="__span-8-9"><a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a>        100 /var/lib/dpkg/status
</span></code></pre></div></p>
<p>安装cuda
<div class="language-text highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a>apt install nvidia-cuda-toolkit
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a>
</span><span id="__span-9-3"><a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a>root@icarus3:/home/nfs/fyyuan# nvcc -V
</span><span id="__span-9-4"><a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a>nvcc: NVIDIA (R) Cuda compiler driver
</span><span id="__span-9-5"><a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a>Copyright (c) 2005-2019 NVIDIA Corporation
</span><span id="__span-9-6"><a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a>Built on Sun_Jul_28_19:07:16_PDT_2019
</span><span id="__span-9-7"><a id="__codelineno-9-7" name="__codelineno-9-7" href="#__codelineno-9-7"></a>Cuda compilation tools, release 10.1, V10.1.243
</span></code></pre></div></p>
<p>版本太老，为10.1的</p>
<p>i0上有许多apt source
- cuda-ubuntu2004-12-1-local.list对应/var/cuda-repo-ubuntu2004-12-1-local/，包含很多deb文件
- cuda-ubuntu2004-x86_64.list为https://developer.download.nvidia.com/compute/cuda
  <code>deb [signed-by=/usr/share/keyrings/cuda-archive-keyring.gpg] https://developer.download.nvidia.com/compute/cuda    /repos/ubuntu2004/x86_64/ /</code>
- source.list中还直接包含<code>deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /</code>
<div class="language-text highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a>root@icarus0:/usr/local/cuda-12.1/bin# ls /etc/apt/sources.list.d/
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>cuda-ubuntu2004-12-1-local.list       docker.list       nvidia-container-toolkit.list.save
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a>cuda-ubuntu2004-12-1-local.list.save  docker.list.save  nvidia-docker.list.save
</span><span id="__span-10-4"><a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a>cuda-ubuntu2004-x86_64.list           mlnx.list
</span><span id="__span-10-5"><a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a>cuda-ubuntu2004-x86_64.list.save      mlnx.list.save
</span></code></pre></div></p>
<p>官网按照deb(network)，发现添加了源，设置了
<div class="language-text highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a>root@icarus3:/home/nfs/fyyuan# apt install cuda
</span><span id="__span-11-2"><a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>Reading package lists... Done
</span><span id="__span-11-3"><a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>Building dependency tree
</span><span id="__span-11-4"><a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a>Reading state information... Done
</span><span id="__span-11-5"><a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a>The following additional packages will be installed:
</span><span id="__span-11-6"><a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a>  cuda-12-1 cuda-cccl-12-1 cuda-command-line-tools-12-1 cuda-compiler-12-1 cuda-cudart-12-1 cuda-cudart-dev-12-1 cuda-cuobjdump-12-1 cuda-cupti-12-1
</span><span id="__span-11-7"><a id="__codelineno-11-7" name="__codelineno-11-7" href="#__codelineno-11-7"></a>  cuda-cupti-dev-12-1 cuda-cuxxfilt-12-1 cuda-demo-suite-12-1 cuda-documentation-12-1 cuda-driver-dev-12-1 cuda-drivers cuda-drivers-530 cuda-gdb-12-1
</span><span id="__span-11-8"><a id="__codelineno-11-8" name="__codelineno-11-8" href="#__codelineno-11-8"></a>  cuda-libraries-12-1 cuda-libraries-dev-12-1 cuda-nsight-12-1 cuda-nsight-compute-12-1 cuda-nsight-systems-12-1 cuda-nvcc-12-1 cuda-nvdisasm-12-1
</span><span id="__span-11-9"><a id="__codelineno-11-9" name="__codelineno-11-9" href="#__codelineno-11-9"></a>  cuda-nvml-dev-12-1 cuda-nvprof-12-1 cuda-nvprune-12-1 cuda-nvrtc-12-1 cuda-nvrtc-dev-12-1 cuda-nvtx-12-1 cuda-nvvp-12-1 cuda-opencl-12-1
</span><span id="__span-11-10"><a id="__codelineno-11-10" name="__codelineno-11-10" href="#__codelineno-11-10"></a>  cuda-opencl-dev-12-1 cuda-profiler-api-12-1 cuda-runtime-12-1 cuda-sanitizer-12-1 cuda-toolkit-12-1 cuda-toolkit-12-1-config-common
</span><span id="__span-11-11"><a id="__codelineno-11-11" name="__codelineno-11-11" href="#__codelineno-11-11"></a>  cuda-toolkit-12-config-common cuda-toolkit-config-common cuda-tools-12-1 cuda-visual-tools-12-1 default-jre default-jre-headless gds-tools-12-1
</span><span id="__span-11-12"><a id="__codelineno-11-12" name="__codelineno-11-12" href="#__codelineno-11-12"></a>  libcublas-12-1 libcublas-dev-12-1 libcufft-12-1 libcufft-dev-12-1 libcufile-12-1 libcufile-dev-12-1 libcurand-12-1 libcurand-dev-12-1 libcusolver-12-1
</span><span id="__span-11-13"><a id="__codelineno-11-13" name="__codelineno-11-13" href="#__codelineno-11-13"></a>  libcusolver-dev-12-1 libcusparse-12-1 libcusparse-dev-12-1 libnpp-12-1 libnpp-dev-12-1 libnvjitlink-12-1 libnvjitlink-dev-12-1 libnvjpeg-12-1
</span><span id="__span-11-14"><a id="__codelineno-11-14" name="__codelineno-11-14" href="#__codelineno-11-14"></a>  libnvjpeg-dev-12-1 libnvvm-samples-12-1 nsight-compute-2023.1.1 nsight-systems-2023.1.2 nvidia-modprobe nvidia-settings openjdk-11-jre
</span><span id="__span-11-15"><a id="__codelineno-11-15" name="__codelineno-11-15" href="#__codelineno-11-15"></a>  openjdk-11-jre-headless
</span><span id="__span-11-16"><a id="__codelineno-11-16" name="__codelineno-11-16" href="#__codelineno-11-16"></a>Suggested packages:
</span><span id="__span-11-17"><a id="__codelineno-11-17" name="__codelineno-11-17" href="#__codelineno-11-17"></a>  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei | fonts-wqy-zenhei fonts-indic
</span><span id="__span-11-18"><a id="__codelineno-11-18" name="__codelineno-11-18" href="#__codelineno-11-18"></a>The following NEW packages will be installed:
</span><span id="__span-11-19"><a id="__codelineno-11-19" name="__codelineno-11-19" href="#__codelineno-11-19"></a>  cuda cuda-12-1 cuda-cccl-12-1 cuda-command-line-tools-12-1 cuda-compiler-12-1 cuda-cudart-12-1 cuda-cudart-dev-12-1 cuda-cuobjdump-12-1 cuda-cupti-12-1
</span><span id="__span-11-20"><a id="__codelineno-11-20" name="__codelineno-11-20" href="#__codelineno-11-20"></a>  cuda-cupti-dev-12-1 cuda-cuxxfilt-12-1 cuda-demo-suite-12-1 cuda-documentation-12-1 cuda-driver-dev-12-1 cuda-drivers cuda-drivers-530 cuda-gdb-12-1
</span><span id="__span-11-21"><a id="__codelineno-11-21" name="__codelineno-11-21" href="#__codelineno-11-21"></a>  cuda-libraries-12-1 cuda-libraries-dev-12-1 cuda-nsight-12-1 cuda-nsight-compute-12-1 cuda-nsight-systems-12-1 cuda-nvcc-12-1 cuda-nvdisasm-12-1
</span><span id="__span-11-22"><a id="__codelineno-11-22" name="__codelineno-11-22" href="#__codelineno-11-22"></a>  cuda-nvml-dev-12-1 cuda-nvprof-12-1 cuda-nvprune-12-1 cuda-nvrtc-12-1 cuda-nvrtc-dev-12-1 cuda-nvtx-12-1 cuda-nvvp-12-1 cuda-opencl-12-1
</span><span id="__span-11-23"><a id="__codelineno-11-23" name="__codelineno-11-23" href="#__codelineno-11-23"></a>  cuda-opencl-dev-12-1 cuda-profiler-api-12-1 cuda-runtime-12-1 cuda-sanitizer-12-1 cuda-toolkit-12-1 cuda-toolkit-12-1-config-common
</span><span id="__span-11-24"><a id="__codelineno-11-24" name="__codelineno-11-24" href="#__codelineno-11-24"></a>  cuda-toolkit-12-config-common cuda-toolkit-config-common cuda-tools-12-1 cuda-visual-tools-12-1 default-jre default-jre-headless gds-tools-12-1
</span><span id="__span-11-25"><a id="__codelineno-11-25" name="__codelineno-11-25" href="#__codelineno-11-25"></a>  libcublas-12-1 libcublas-dev-12-1 libcufft-12-1 libcufft-dev-12-1 libcufile-12-1 libcufile-dev-12-1 libcurand-12-1 libcurand-dev-12-1 libcusolver-12-1
</span><span id="__span-11-26"><a id="__codelineno-11-26" name="__codelineno-11-26" href="#__codelineno-11-26"></a>  libcusolver-dev-12-1 libcusparse-12-1 libcusparse-dev-12-1 libnpp-12-1 libnpp-dev-12-1 libnvjitlink-12-1 libnvjitlink-dev-12-1 libnvjpeg-12-1
</span><span id="__span-11-27"><a id="__codelineno-11-27" name="__codelineno-11-27" href="#__codelineno-11-27"></a>  libnvjpeg-dev-12-1 libnvvm-samples-12-1 nsight-compute-2023.1.1 nsight-systems-2023.1.2 nvidia-modprobe openjdk-11-jre openjdk-11-jre-headless
</span><span id="__span-11-28"><a id="__codelineno-11-28" name="__codelineno-11-28" href="#__codelineno-11-28"></a>The following packages will be upgraded:
</span><span id="__span-11-29"><a id="__codelineno-11-29" name="__codelineno-11-29" href="#__codelineno-11-29"></a>  nvidia-settings
</span><span id="__span-11-30"><a id="__codelineno-11-30" name="__codelineno-11-30" href="#__codelineno-11-30"></a>1 upgraded, 69 newly installed, 0 to remove and 59 not upgraded.
</span><span id="__span-11-31"><a id="__codelineno-11-31" name="__codelineno-11-31" href="#__codelineno-11-31"></a>Need to get 2802 MB of archives.
</span><span id="__span-11-32"><a id="__codelineno-11-32" name="__codelineno-11-32" href="#__codelineno-11-32"></a>After this operation, 6511 MB of additional disk space will be used.
</span><span id="__span-11-33"><a id="__codelineno-11-33" name="__codelineno-11-33" href="#__codelineno-11-33"></a>Do you want to continue? [Y/n]
</span></code></pre></div></p>
<h2 id="nvcc">NVCC<a class="headerlink" href="#nvcc" title="Permanent link">&para;</a></h2>
<h3 id="两阶段编译">两阶段编译<a class="headerlink" href="#两阶段编译" title="Permanent link">&para;</a></h3>
<p>GPU不同generation，二进制程序是不兼容的。为了保证应用的兼容性，采用了两阶段编译。</p>
<p><a href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#virtual-architectures">NVIDIA CUDA Compiler Driver</a>
- nvcc总是需要使用两个架构:虚拟架构(compute_xx)和真实架构(sm_xx)
- sm必须实现了compute的功能
- 虚拟架构表明了应用使用到的能力，使用更低的虚拟架构允许在更广泛的硬件上运行
- 真实架构越高，生成的代码就更高效（硬件特性更多）
<img alt="" src="https://raw.githubusercontent.com/TheRainstorm/.image-bed/main/20231122142044.png" /></p>
<h3 id="jit机制">JIT机制<a class="headerlink" href="#jit机制" title="Permanent link">&para;</a></h3>
<ul>
<li>将cubin生成推迟到运行时</li>
<li>缺点是增加了应用startup延迟
<img alt="" src="https://raw.githubusercontent.com/TheRainstorm/.image-bed/main/20231122143033.png" /></li>
</ul>
<p>By specifying a virtual code architecture instead of a <em>real</em> GPU, <code>nvcc</code> postpones the assembly of PTX code until application runtime, at which time the target GPU is exactly known.
<div class="language-text highlight"><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a>nvcc x.cu --gpu-architecture=compute_50 --gpu-code=compute_50
</span></code></pre></div></p>
<h3 id="fatbinaries">fatbinaries<a class="headerlink" href="#fatbinaries" title="Permanent link">&para;</a></h3>
<p>A different solution to overcome startup delay by JIT while still allowing execution on newer GPUs is to specify multiple code instances
<div class="language-text highlight"><pre><span></span><code><span id="__span-13-1"><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a>nvcc x.cu --gpu-architecture=compute_50 --gpu-code=compute_50,sm_50,sm_52
</span></code></pre></div></p>
<h3 id="example">example<a class="headerlink" href="#example" title="Permanent link">&para;</a></h3>
<p><a href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#nvcc-examples">NVIDIA CUDA Compiler Driver</a></p>
<p><code>--gpu-architecture</code>或<code>-arch</code></p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-14-1"><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a>nvcc x.cu --gpu-architecture=compute_50 --gpu-code=sm_50,sm_52
</span></code></pre></div>
<h4 id="jit">JIT<a class="headerlink" href="#jit" title="Permanent link">&para;</a></h4>
<p>gpu-code如果也指定虚拟架构，表明使用JIT
<code>--gpu-code</code> arguments can be virtual architectures. In this case the stage 2 translation will be omitted for such virtual architecture, and the stage 1 PTX result will be embedded instead. At application launch, and in case the driver does not find a better alternative, the stage 2 compilation will be invoked by the driver with the PTX as input.
<div class="language-text highlight"><pre><span></span><code><span id="__span-15-1"><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a>nvcc x.cu --gpu-architecture=compute_50 --gpu-code=compute_50,sm_50,sm_52
</span></code></pre></div></p>
<h4 id="省略gpu-code">省略gpu-code<a class="headerlink" href="#省略gpu-code" title="Permanent link">&para;</a></h4>
<p><div class="language-text highlight"><pre><span></span><code><span id="__span-16-1"><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a>nvcc x.cu --gpu-architecture=sm_52
</span><span id="__span-16-2"><a id="__codelineno-16-2" name="__codelineno-16-2" href="#__codelineno-16-2"></a>nvcc x.cu --gpu-architecture=compute_50
</span></code></pre></div>
分别等价于
<div class="language-text highlight"><pre><span></span><code><span id="__span-17-1"><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a>nvcc x.cu --gpu-architecture=compute_52 --gpu-code=sm_52,compute_52
</span><span id="__span-17-2"><a id="__codelineno-17-2" name="__codelineno-17-2" href="#__codelineno-17-2"></a>nvcc x.cu --gpu-architecture=compute_50 --gpu-code=compute_50
</span></code></pre></div></p>
<h4 id="同时省略arch-gpu-code">同时省略arch, gpu-code<a class="headerlink" href="#同时省略arch-gpu-code" title="Permanent link">&para;</a></h4>
<p>默认使用sm_52？
<div class="language-text highlight"><pre><span></span><code><span id="__span-18-1"><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a>nvcc x.cu
</span><span id="__span-18-2"><a id="__codelineno-18-2" name="__codelineno-18-2" href="#__codelineno-18-2"></a># 等价于
</span><span id="__span-18-3"><a id="__codelineno-18-3" name="__codelineno-18-3" href="#__codelineno-18-3"></a>nvcc x.cu --gpu-architecture=compute_52 --gpu-code=sm_52,compute_52
</span></code></pre></div></p>
<h4 id="-generate-code指定多种组合">-generate-code指定多种组合<a class="headerlink" href="#-generate-code指定多种组合" title="Permanent link">&para;</a></h4>
<p>使用一个虚拟架构，限制了功能。可以为不同硬件指定不同虚拟架构</p>
<blockquote>
<p><code>compute_50</code> assumes no half-precision floating-point operation support for both the <code>sm_50</code> code and the <code>sm_53</code> code:</p>
</blockquote>
<div class="language-text highlight"><pre><span></span><code><span id="__span-19-1"><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a>nvcc x.cu \
</span><span id="__span-19-2"><a id="__codelineno-19-2" name="__codelineno-19-2" href="#__codelineno-19-2"></a>    --generate-code arch=compute_50,code=sm_50 \
</span><span id="__span-19-3"><a id="__codelineno-19-3" name="__codelineno-19-3" href="#__codelineno-19-3"></a>    --generate-code arch=compute_50,code=sm_52 \
</span><span id="__span-19-4"><a id="__codelineno-19-4" name="__codelineno-19-4" href="#__codelineno-19-4"></a>    --generate-code arch=compute_53,code=sm_53
</span></code></pre></div>
<h3 id="nvcc选项">nvcc选项<a class="headerlink" href="#nvcc选项" title="Permanent link">&para;</a></h3>
<p>On all platforms, the default host compiler executable (<code>gcc</code> and <code>g++</code> on Linux and <code>cl.exe</code> on Windows) found in the current execution search path will be used, unless specified otherwise with appropriate options
<img alt="" src="https://raw.githubusercontent.com/TheRainstorm/.image-bed/main/20231122143333.png" /></p>
<p><a href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#options-for-steering-gpu-code-generation">NVIDIA CUDA Compiler Driver</a></p>
<p>When <code>-arch=native</code> is specified, <code>nvcc</code> detects the visible GPUs on the system and generates codes for them, no PTX program will be generated for this option. It is a warning if there are no visible supported GPU on the system, and the default architecture will be used.</p>
<p>If <code>-arch=all</code> is specified, <code>nvcc</code> embeds a compiled code image for all supported architectures <code>(sm_*)</code>, and a PTX program for the highest major virtual architecture. For <code>-arch=all-major</code>, <code>nvcc</code> embeds a compiled code image for all supported major versions <code>(sm_*0)</code>, plus the earliest supported, and adds a PTX program for the highest major virtual architecture.</p>
<h4 id="环境变量">环境变量<a class="headerlink" href="#环境变量" title="Permanent link">&para;</a></h4>
<p>https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#nvcc-environment-variables</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-20-1"><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a>export NVCC_PREPEND_FLAGS=&#39;-G -keep -arch=sm_60&#39;
</span><span id="__span-20-2"><a id="__codelineno-20-2" name="__codelineno-20-2" href="#__codelineno-20-2"></a>export NVCC_APPEND_FLAGS=&#39;-DNAME=&quot; foo &quot;&#39;
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-21-1"><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a>nvcc foo.cu -o foo
</span><span id="__span-21-2"><a id="__codelineno-21-2" name="__codelineno-21-2" href="#__codelineno-21-2"></a># 等价于
</span><span id="__span-21-3"><a id="__codelineno-21-3" name="__codelineno-21-3" href="#__codelineno-21-3"></a>nvcc -G -keep -arch=sm_60 foo.cu -o foo -DNAME=&quot; foo &quot;
</span></code></pre></div>
<h2 id="cuda编程">Cuda编程<a class="headerlink" href="#cuda编程" title="Permanent link">&para;</a></h2>
<h3 id="统一内存模型">统一内存模型<a class="headerlink" href="#统一内存模型" title="Permanent link">&para;</a></h3>
<p>在 CUDA 编程中，<code>__managed__</code> 是一个 CUDA 扩展关键字，用于标识被修饰的变量或数据结构将在主机（CPU）和设备（GPU）之间自动进行内存管理。它是 CUDA Unified Memory 功能的一部分，旨在简化主机和设备之间的内存管理和数据传输。</p>
<p>通过使用 <code>__managed__</code> 关键字，您可以将变量或数据结构声明为统一内存（Unified Memory）。这意味着在使用这些统一内存对象时，无需显式地在主机和设备之间进行手动内存分配和数据传输。CUDA 运行时系统会自动处理内存的分配和迁移，以确保数据在主机和设备之间正确共享。</p>
<h3 id="同步">同步<a class="headerlink" href="#同步" title="Permanent link">&para;</a></h3>
<p><a href="https://stackoverflow.com/questions/15240432/does-syncthreads-synchronize-all-threads-in-the-grid">cuda - Does __syncthreads() synchronize all threads in the grid? - Stack Overflow</a>
<div class="language-text highlight"><pre><span></span><code><span id="__span-22-1"><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a>__syncthreads()  // 该函数同步block内线程（实际是warp，warp内线程执行的是相同指令，本身就是同步的）
</span></code></pre></div></p>
<ul>
<li>cudaDeviceSynchronize</li>
<li>CPU等待GPU完成kernel调用</li>
</ul>
<p>CUDA没有全局同步（block间同步）
- 对于SM数量很大的GPU，硬件成本太高
- would force programmer to run fewer blocks (no more than # multiprocessors * # resident blocks / multiprocessor) to avoid deadlock, which may reduce overall efficiency
解决办法：
分解为多个kernel
- kernel launch作为global sync point
- kernel launch has negligible HW overhead, low SW overhead</p>
<h3 id="cublas">cuBLAS<a class="headerlink" href="#cublas" title="Permanent link">&para;</a></h3>
<p>计算矩阵A x B
方式一：
<div class="language-text highlight"><pre><span></span><code><span id="__span-23-1"><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a>cublasSgemm (blas_handle, CUBLAS_OP_T, CUBLAS_OP_T,   //CUBLAS使用列优先存储。CUBLAS_OP_T表示进行转置，即行优先。列优先下leading dimesion为m(mxn矩阵)
</span><span id="__span-23-2"><a id="__codelineno-23-2" name="__codelineno-23-2" href="#__codelineno-23-2"></a>                     m, n, k,
</span><span id="__span-23-3"><a id="__codelineno-23-3" name="__codelineno-23-3" href="#__codelineno-23-3"></a>                     &amp;alpha,
</span><span id="__span-23-4"><a id="__codelineno-23-4" name="__codelineno-23-4" href="#__codelineno-23-4"></a>                     d_A, k, d_B, n,
</span><span id="__span-23-5"><a id="__codelineno-23-5" name="__codelineno-23-5" href="#__codelineno-23-5"></a>                     &amp;beta,
</span><span id="__span-23-6"><a id="__codelineno-23-6" name="__codelineno-23-6" href="#__codelineno-23-6"></a>                     d_C, n); //结果仍为列优先，故计算得到C的转置
</span></code></pre></div>
方式二：
<div class="language-text highlight"><pre><span></span><code><span id="__span-24-1"><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a>/* 通过计算B^T * A^T得到C^T，由于列优先所有d_C实际为C的行优先结果。 //https://stackoverflow.com/a/56064726
</span><span id="__span-24-2"><a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a>        疑问：这里beta等于0，故C的初始值没有影响，行列优先均可（ldc=m, n均正确）。但是如果非0，那么如何处理呢？
</span><span id="__span-24-3"><a id="__codelineno-24-3" name="__codelineno-24-3" href="#__codelineno-24-3"></a>        */
</span><span id="__span-24-4"><a id="__codelineno-24-4" name="__codelineno-24-4" href="#__codelineno-24-4"></a>        cublasSgemm(blas_handle, CUBLAS_OP_N, CUBLAS_OP_N,
</span><span id="__span-24-5"><a id="__codelineno-24-5" name="__codelineno-24-5" href="#__codelineno-24-5"></a>                    n, m, k,
</span><span id="__span-24-6"><a id="__codelineno-24-6" name="__codelineno-24-6" href="#__codelineno-24-6"></a>                    &amp;alpha,
</span><span id="__span-24-7"><a id="__codelineno-24-7" name="__codelineno-24-7" href="#__codelineno-24-7"></a>                    d_B, n, d_A, k,
</span><span id="__span-24-8"><a id="__codelineno-24-8" name="__codelineno-24-8" href="#__codelineno-24-8"></a>                    &amp;beta,
</span><span id="__span-24-9"><a id="__codelineno-24-9" name="__codelineno-24-9" href="#__codelineno-24-9"></a>                    d_C, n);
</span></code></pre></div></p>
<h1 id="工具">工具<a class="headerlink" href="#工具" title="Permanent link">&para;</a></h1>
<ul>
<li>IDE/debug/profile工具预览：<a href="https://developer.nvidia.com/tools-overview">NVIDIA Developer Tools Overview | NVIDIA Developer</a></li>
</ul>
<p>Which tools are available on which GPU architectures</p>
<table>
<thead>
<tr>
<th>GPU architecture</th>
<th>Visual Profiler and nvprof</th>
<th>Nsight Systems</th>
<th>Nsight Compute</th>
</tr>
</thead>
<tbody>
<tr>
<td>Maxwell</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td>Pascal</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr>
<td>Volta</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Turing</td>
<td>Yes*</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Ampere and later GPU architectures</td>
<td>No</td>
<td>Yes</td>
<td>Yes</td>
</tr>
</tbody>
</table>
<p>nsight sytem
- high level</p>
<p>nsight compute
- detailed
- performance metrics</p>
<h2 id="nvprof">nvprof<a class="headerlink" href="#nvprof" title="Permanent link">&para;</a></h2>
<p>The <a href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html#visual-profiler">Visual Profiler</a> is a graphical profiling tool that displays a timeline of your application’s CPU and GPU activity, and that includes an automated analysis engine to identify optimization opportunities. The <a href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html#nvprof">nvprof</a> profiling tool enables you to collect and view profiling data from the command-line.</p>
<p><strong>Note that Visual Profiler and nvprof will be deprecated in a future CUDA release.</strong> The NVIDIA Volta platform is the last architecture on which these tools are fully supported. It is recommended to use next-generation tools <a href="https://developer.nvidia.com/nsight-systems">NVIDIA Nsight Systems</a> for GPU and CPU sampling and tracing and <a href="https://developer.nvidia.com/nsight-compute">NVIDIA Nsight Compute</a> for GPU kernel profiling.</p>
<h3 id="visual-profilernvvp">Visual Profiler/nvvp<a class="headerlink" href="#visual-profilernvvp" title="Permanent link">&para;</a></h3>
<p><a href="https://developer.nvidia.com/nvidia-visual-profiler">NVIDIA Visual Profiler | NVIDIA Developer</a></p>
<p>https://docs.nvidia.com/cuda/profiler-users-guide/index.html#visual-profiler</p>
<p>The Visual Profiler is available as both a standalone application and as part of Nsight Eclipse Edition. The standalone version of the Visual Profiler, <code>nvvp</code>, is included in the CUDA Toolkit for all supported OSes except for macOS.</p>
<p>步骤
- 安装设置1.8 JRE
- Preparing An Application For Profiling
- create session: A session contains the settings, data, and profiling results associated with your application. Each session is saved in a separate file; so you can delete, move, copy, or share a session by simply deleting, moving, copying, or sharing the session file. By convention, the file extension <code>.nvvp</code> is used for Visual Profiler session files.
- analyziing</p>
<h4 id="java版本">java版本<a class="headerlink" href="#java版本" title="Permanent link">&para;</a></h4>
<p>需要Java Runtime Environment (JRE) 1.8
可以启动时通过vm指定
<div class="language-text highlight"><pre><span></span><code><span id="__span-25-1"><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a>nvvp -vm /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java
</span></code></pre></div></p>
<p>也可以设置全局java版本
<code>update-alternatives</code> 是一个 Debian 系统中用于管理多个软件版本的工具。通过它，你可以轻松切换默认使用的 Java 版本
<div class="language-text highlight"><pre><span></span><code><span id="__span-26-1"><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a>sudo update-alternatives --config java
</span></code></pre></div></p>
<h4 id="ioexception-locking-file">IOException: locking file<a class="headerlink" href="#ioexception-locking-file" title="Permanent link">&para;</a></h4>
<div class="language-text highlight"><pre><span></span><code><span id="__span-27-1"><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a>(base) fyyuan@snode6 ➜  ~ nvvp -vm /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java
</span><span id="__span-27-2"><a id="__codelineno-27-2" name="__codelineno-27-2" href="#__codelineno-27-2"></a>java.lang.RuntimeException: Error initializing storage.
</span><span id="__span-27-3"><a id="__codelineno-27-3" name="__codelineno-27-3" href="#__codelineno-27-3"></a>        at org.eclipse.osgi.internal.framework.EquinoxContainer.&lt;init&gt;(EquinoxContainer.java:77)
</span><span id="__span-27-4"><a id="__codelineno-27-4" name="__codelineno-27-4" href="#__codelineno-27-4"></a>        at org.eclipse.osgi.launch.Equinox.&lt;init&gt;(Equinox.java:31)
</span><span id="__span-27-5"><a id="__codelineno-27-5" name="__codelineno-27-5" href="#__codelineno-27-5"></a>        at org.eclipse.core.runtime.adaptor.EclipseStarter.startup(EclipseStarter.java:295)
</span><span id="__span-27-6"><a id="__codelineno-27-6" name="__codelineno-27-6" href="#__codelineno-27-6"></a>        at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:231)
</span><span id="__span-27-7"><a id="__codelineno-27-7" name="__codelineno-27-7" href="#__codelineno-27-7"></a>        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
</span><span id="__span-27-8"><a id="__codelineno-27-8" name="__codelineno-27-8" href="#__codelineno-27-8"></a>        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
</span><span id="__span-27-9"><a id="__codelineno-27-9" name="__codelineno-27-9" href="#__codelineno-27-9"></a>        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
</span><span id="__span-27-10"><a id="__codelineno-27-10" name="__codelineno-27-10" href="#__codelineno-27-10"></a>        at java.lang.reflect.Method.invoke(Method.java:498)
</span><span id="__span-27-11"><a id="__codelineno-27-11" name="__codelineno-27-11" href="#__codelineno-27-11"></a>        at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:648)
</span><span id="__span-27-12"><a id="__codelineno-27-12" name="__codelineno-27-12" href="#__codelineno-27-12"></a>        at org.eclipse.equinox.launcher.Main.basicRun(Main.java:603)
</span><span id="__span-27-13"><a id="__codelineno-27-13" name="__codelineno-27-13" href="#__codelineno-27-13"></a>        at org.eclipse.equinox.launcher.Main.run(Main.java:1465)
</span><span id="__span-27-14"><a id="__codelineno-27-14" name="__codelineno-27-14" href="#__codelineno-27-14"></a>        at org.eclipse.equinox.launcher.Main.main(Main.java:1438)
</span><span id="__span-27-15"><a id="__codelineno-27-15" name="__codelineno-27-15" href="#__codelineno-27-15"></a>Caused by: java.io.IOException: An error occurred while locking file &quot;/staff/fyyuan/.eclipse/org.eclipse.platform_4.4.1_868875438_linux_gtk_x86_64/configuration/org.eclipse.osgi/.manager/.fileTableLock&quot;: &quot;Input/output error&quot;. A common reason is that the file system or Runtime Environment does not support file locking for that location. Please choose a different location, or disable file locking by passing &quot;-Dosgi.locking=none&quot; as a VM argument.
</span><span id="__span-27-16"><a id="__codelineno-27-16" name="__codelineno-27-16" href="#__codelineno-27-16"></a>        at org.eclipse.osgi.internal.location.Locker_JavaNio.lock(Locker_JavaNio.java:49)
</span><span id="__span-27-17"><a id="__codelineno-27-17" name="__codelineno-27-17" href="#__codelineno-27-17"></a>        at org.eclipse.osgi.storagemanager.StorageManager.lock(StorageManager.java:388)
</span><span id="__span-27-18"><a id="__codelineno-27-18" name="__codelineno-27-18" href="#__codelineno-27-18"></a>        at org.eclipse.osgi.storagemanager.StorageManager.open(StorageManager.java:701)
</span><span id="__span-27-19"><a id="__codelineno-27-19" name="__codelineno-27-19" href="#__codelineno-27-19"></a>        at org.eclipse.osgi.storage.Storage.getChildStorageManager(Storage.java:1747)
</span><span id="__span-27-20"><a id="__codelineno-27-20" name="__codelineno-27-20" href="#__codelineno-27-20"></a>        at org.eclipse.osgi.storage.Storage.getInfoInputStream(Storage.java:1764)
</span><span id="__span-27-21"><a id="__codelineno-27-21" name="__codelineno-27-21" href="#__codelineno-27-21"></a>        at org.eclipse.osgi.storage.Storage.&lt;init&gt;(Storage.java:124)
</span><span id="__span-27-22"><a id="__codelineno-27-22" name="__codelineno-27-22" href="#__codelineno-27-22"></a>        at org.eclipse.osgi.storage.Storage.createStorage(Storage.java:84)
</span><span id="__span-27-23"><a id="__codelineno-27-23" name="__codelineno-27-23" href="#__codelineno-27-23"></a>        at org.eclipse.osgi.internal.framework.EquinoxContainer.&lt;init&gt;(EquinoxContainer.java:75)
</span><span id="__span-27-24"><a id="__codelineno-27-24" name="__codelineno-27-24" href="#__codelineno-27-24"></a>        ... 11 more
</span></code></pre></div>
<p>提示的添加vm参数方法，添加到cuda-tookit-dir/libnvvp/nvvp.ini结尾（使用-vmargs指定）
<div class="language-text highlight"><pre><span></span><code><span id="__span-28-1"><a id="__codelineno-28-1" name="__codelineno-28-1" href="#__codelineno-28-1"></a>sudo vim /usr/local/cuda-11.8/libnvvp/nvvp.ini
</span><span id="__span-28-2"><a id="__codelineno-28-2" name="__codelineno-28-2" href="#__codelineno-28-2"></a>
</span><span id="__span-28-3"><a id="__codelineno-28-3" name="__codelineno-28-3" href="#__codelineno-28-3"></a>-startup
</span><span id="__span-28-4"><a id="__codelineno-28-4" name="__codelineno-28-4" href="#__codelineno-28-4"></a>plugins/org.eclipse.equinox.launcher_1.3.0.v20140415-2008.jar
</span><span id="__span-28-5"><a id="__codelineno-28-5" name="__codelineno-28-5" href="#__codelineno-28-5"></a>--launcher.library
</span><span id="__span-28-6"><a id="__codelineno-28-6" name="__codelineno-28-6" href="#__codelineno-28-6"></a>plugins/org.eclipse.equinox.launcher.gtk.linux.x86_64_1.1.200.v20140603-1326
</span><span id="__span-28-7"><a id="__codelineno-28-7" name="__codelineno-28-7" href="#__codelineno-28-7"></a>-data
</span><span id="__span-28-8"><a id="__codelineno-28-8" name="__codelineno-28-8" href="#__codelineno-28-8"></a>@noDefault
</span><span id="__span-28-9"><a id="__codelineno-28-9" name="__codelineno-28-9" href="#__codelineno-28-9"></a>-vmargs
</span><span id="__span-28-10"><a id="__codelineno-28-10" name="__codelineno-28-10" href="#__codelineno-28-10"></a>-Dosgi.locking=none
</span></code></pre></div></p>
<h3 id="pc-sample-view">PC sample View<a class="headerlink" href="#pc-sample-view" title="Permanent link">&para;</a></h3>
<ul>
<li>compute_52支持PC采样。<ul>
<li>PC and state of warp are sampled at regular interval for one of the active warps per SM</li>
<li>The warp state indicates if that warp issued an instruction in a cycle or why it was stalled and could not issue an instruction</li>
<li>Hence the stall for the sampled warp need <strong>not necessarily indicate that there is a hole</strong> in the instruction issue pipeline.</li>
</ul>
</li>
<li><strong>compute_60支持 latency reasons</strong><ul>
<li>While collecting these samples, <strong>there is no instruction issued in the respective warp scheduler</strong> and hence these give the latency reasons.</li>
</ul>
</li>
</ul>
<p>6.0以上设备，Visual Profiler show two views: ‘Kernel Profile - PC Sampling’ which gives the warp state view and ‘Kernel Profile - PC Sampling - Latency’ which gives the latency reasons.</p>
<h3 id="memory统计">memory统计<a class="headerlink" href="#memory统计" title="Permanent link">&para;</a></h3>
<ul>
<li>The data paths from the SMs to the memory spaces (Global, Local, Texture, Surface and Shared) report the total number of memory instructions executed, it includes both read and write operations.</li>
<li>The data path between memory spaces and “Unified Cache” or “Shared Memory” reports the total amount of memory requests made.</li>
<li>All other data paths report the total amount of transferred memory in bytes.</li>
</ul>
<p><img alt="" src="https://docs.nvidia.com/cuda/profiler-users-guide/_images/analysis-view-memory-stat.png" /></p>
<h3 id="source-disassembly">source-disassembly<a class="headerlink" href="#source-disassembly" title="Permanent link">&para;</a></h3>
<p><code>-lineinfo</code></p>
<h3 id="warp-statestall原因">Warp state/stall原因<a class="headerlink" href="#warp-statestall原因" title="Permanent link">&para;</a></h3>
<p><a href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html#pc-sampling-view">1. Preparing An Application For Profiling — Profiler 12.3 documentation (nvidia.com)</a></p>
<p>https://docs.nvidia.com/cuda/profiler-users-guide/index.html#warp-state</p>
<p>能够对应到源码进行分析：<a href="https://developer.nvidia.com/blog/cuda-7-5-pinpoint-performance-problems-instruction-level-profiling/">CUDA 7.5: Pinpoint Performance Problems with Instruction-Level Profiling | NVIDIA Technical Blog</a></p>
<p><img alt="" src="https://raw.githubusercontent.com/TheRainstorm/.image-bed/main/20231215143416.png" /></p>
<ul>
<li><strong>Instruction issued</strong></li>
<li><strong>Stalled</strong><ul>
<li><strong>Stalled for instruction fetch</strong><ul>
<li>For very short kernels, consider fusing into a single kernels.</li>
</ul>
</li>
<li><strong>Stalled for execution dependency</strong></li>
<li><strong>Stalled for memory dependency</strong><ul>
<li>尝试提高内存合并和/或获取字节的效率（对齐等）。使用gld_efficiency和gst_efficiency检查未合并的内存访问</li>
<li>memory-level parallelism (MLP): the number of independent memory operations in flight per thread. Loop unrolling, loading vector types such as float4, and processing multiple elements per thread are all ways to increase memory-level parallelism.</li>
<li>请考虑将经常访问的数据移动到更靠近 SM 的位置，例如使用共享内存或只读数据缓存。</li>
<li>考虑尽可能重新计算数据，而不是从设备内存加载数据</li>
<li>如果本地内存访问量很高，请考虑增加每个线程的寄存器计数以减少溢出，即使以占用率为代价</li>
</ul>
</li>
<li><strong>Stalled for memory throttle</strong></li>
<li><strong>Stalled for texture</strong></li>
<li><strong>Stalled for sync</strong></li>
<li><strong>Stalled for constant memory dependency</strong></li>
<li><strong>Stalled for pipe busy</strong>：functional unit busy</li>
<li><strong>Stalled for not selected</strong>：Warp 已准备就绪，但没有机会发出，因为选择了其他一些 Warp 进行发出。</li>
<li><strong>Stalled for other</strong>：Warp 因不常见的原因（如编译器或硬件原因）而被阻止。开发人员无法控制这些stall。</li>
</ul>
</li>
</ul>
<h2 id="nvprof_1">nvprof<a class="headerlink" href="#nvprof_1" title="Permanent link">&para;</a></h2>
<ul>
<li>Summary Mode<ul>
<li>默认模式，<code>nvprof</code> outputs a single result line for each kernel function and each type of CUDA memory copy/set performed by the application.</li>
<li>如果不需要，可以使用 关闭 API 跟踪 <code>--profile-api-trace none</code> 。这减少了一些性能分析开销，尤其是在内核较短时。</li>
</ul>
</li>
<li>gpu-trace<ul>
<li>GPU-Trace mode provides a timeline of all activities taking place on the GPU in chronological order.</li>
<li>按照时间顺序显示。同一个kernel会多次显示</li>
<li><code>nvprof --print-gpu-trace matrixMul</code></li>
</ul>
</li>
<li>API-trace: API-trace mode shows the timeline of all CUDA runtime and driver API calls invoked on the host in chronological order.<ul>
<li>显示runtime和driver API调用</li>
<li><code>nvprof --print-api-trace matrixMul</code></li>
</ul>
</li>
<li>Event/metric Summary Mode<ul>
<li><code>--events all</code> <code>--metrics all</code></li>
</ul>
</li>
</ul>
<p>An <strong>event</strong> is a countable activity, action, or occurrence on a device. It corresponds to a single hardware counter value which is collected during kernel execution. To see a list of all available events on a particular NVIDIA GPU, type <code>nvprof --query-events</code>.</p>
<p>A <strong>metric</strong> is a characteristic of an application that is calculated from one or more event values. To see a list of all available metrics on a particular NVIDIA GPU, type <code>nvprof --query-metrics</code>. You can also refer to the <a href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html#metrics-reference">metrics reference</a> .</p>
<p><code>Usage: nvprof [options] [application] [application-arguments]</code></p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-29-1"><a id="__codelineno-29-1" name="__codelineno-29-1" href="#__codelineno-29-1"></a>--analysis-metrics
</span><span id="__span-29-2"><a id="__codelineno-29-2" name="__codelineno-29-2" href="#__codelineno-29-2"></a>                        Collect profiling data that can be imported to Visual Profiler&#39;s
</span><span id="__span-29-3"><a id="__codelineno-29-3" name="__codelineno-29-3" href="#__codelineno-29-3"></a>                        &quot;analysis&quot; mode. Note: Use &quot;--export-profile&quot; to specify
</span><span id="__span-29-4"><a id="__codelineno-29-4" name="__codelineno-29-4" href="#__codelineno-29-4"></a>                        an export file.
</span><span id="__span-29-5"><a id="__codelineno-29-5" name="__codelineno-29-5" href="#__codelineno-29-5"></a>
</span><span id="__span-29-6"><a id="__codelineno-29-6" name="__codelineno-29-6" href="#__codelineno-29-6"></a>--devices &lt;device ids&gt;
</span><span id="__span-29-7"><a id="__codelineno-29-7" name="__codelineno-29-7" href="#__codelineno-29-7"></a>                        Change the scope of subsequent &quot;--events&quot;, &quot;--metrics&quot;, &quot;--query-events&quot;
</span><span id="__span-29-8"><a id="__codelineno-29-8" name="__codelineno-29-8" href="#__codelineno-29-8"></a>                        and &quot;--query-metrics&quot; options.
</span><span id="__span-29-9"><a id="__codelineno-29-9" name="__codelineno-29-9" href="#__codelineno-29-9"></a>                        Allowed values:
</span><span id="__span-29-10"><a id="__codelineno-29-10" name="__codelineno-29-10" href="#__codelineno-29-10"></a>                                all - change scope to all valid devices
</span><span id="__span-29-11"><a id="__codelineno-29-11" name="__codelineno-29-11" href="#__codelineno-29-11"></a>                                comma-separated device IDs - change scope to specified
</span><span id="__span-29-12"><a id="__codelineno-29-12" name="__codelineno-29-12" href="#__codelineno-29-12"></a>                        devices
</span><span id="__span-29-13"><a id="__codelineno-29-13" name="__codelineno-29-13" href="#__codelineno-29-13"></a>
</span><span id="__span-29-14"><a id="__codelineno-29-14" name="__codelineno-29-14" href="#__codelineno-29-14"></a>  -e,  --events &lt;event names&gt;
</span><span id="__span-29-15"><a id="__codelineno-29-15" name="__codelineno-29-15" href="#__codelineno-29-15"></a>                        Specify the events to be profiled on certain device(s). Multiple
</span><span id="__span-29-16"><a id="__codelineno-29-16" name="__codelineno-29-16" href="#__codelineno-29-16"></a>                        event names separated by comma can be specified. Which device(s)
</span><span id="__span-29-17"><a id="__codelineno-29-17" name="__codelineno-29-17" href="#__codelineno-29-17"></a>                        are profiled is controlled by the &quot;--devices&quot; option. Otherwise
</span><span id="__span-29-18"><a id="__codelineno-29-18" name="__codelineno-29-18" href="#__codelineno-29-18"></a>                        events will be collected on all devices.
</span><span id="__span-29-19"><a id="__codelineno-29-19" name="__codelineno-29-19" href="#__codelineno-29-19"></a>                        For a list of available events, use &quot;--query-events&quot;.
</span><span id="__span-29-20"><a id="__codelineno-29-20" name="__codelineno-29-20" href="#__codelineno-29-20"></a>                        Use &quot;--events all&quot; to profile all events available for each
</span><span id="__span-29-21"><a id="__codelineno-29-21" name="__codelineno-29-21" href="#__codelineno-29-21"></a>                        device.
</span><span id="__span-29-22"><a id="__codelineno-29-22" name="__codelineno-29-22" href="#__codelineno-29-22"></a>                        Use &quot;--devices&quot; and &quot;--kernels&quot; to select a specific kernel
</span><span id="__span-29-23"><a id="__codelineno-29-23" name="__codelineno-29-23" href="#__codelineno-29-23"></a>                        invocation.
</span><span id="__span-29-24"><a id="__codelineno-29-24" name="__codelineno-29-24" href="#__codelineno-29-24"></a> --kernels &lt;kernel path syntax&gt;
</span><span id="__span-29-25"><a id="__codelineno-29-25" name="__codelineno-29-25" href="#__codelineno-29-25"></a>                        Change the scope of subsequent &quot;--events&quot;, &quot;--metrics&quot; options.
</span><span id="__span-29-26"><a id="__codelineno-29-26" name="__codelineno-29-26" href="#__codelineno-29-26"></a>                        The syntax is as follows:
</span><span id="__span-29-27"><a id="__codelineno-29-27" name="__codelineno-29-27" href="#__codelineno-29-27"></a>                                &lt;kernel name&gt;
</span><span id="__span-29-28"><a id="__codelineno-29-28" name="__codelineno-29-28" href="#__codelineno-29-28"></a>                                Limit scope to given kernel name.
</span><span id="__span-29-29"><a id="__codelineno-29-29" name="__codelineno-29-29" href="#__codelineno-29-29"></a>                        or
</span><span id="__span-29-30"><a id="__codelineno-29-30" name="__codelineno-29-30" href="#__codelineno-29-30"></a>                                &lt;context id/name&gt;:&lt;stream id/name&gt;:&lt;kernel name&gt;:&lt;invocation&gt;
</span><span id="__span-29-31"><a id="__codelineno-29-31" name="__codelineno-29-31" href="#__codelineno-29-31"></a>                        The context/stream IDs, names, kernel name and invocation
</span><span id="__span-29-32"><a id="__codelineno-29-32" name="__codelineno-29-32" href="#__codelineno-29-32"></a>                        can be regular expressions. Empty string matches any number
</span><span id="__span-29-33"><a id="__codelineno-29-33" name="__codelineno-29-33" href="#__codelineno-29-33"></a>                        or characters. If &lt;context id/name&gt; or &lt;stream id/name&gt;
</span><span id="__span-29-34"><a id="__codelineno-29-34" name="__codelineno-29-34" href="#__codelineno-29-34"></a>                        is a positive number, it&#39;s strictly matched against the
</span><span id="__span-29-35"><a id="__codelineno-29-35" name="__codelineno-29-35" href="#__codelineno-29-35"></a>                        CUDA context/stream ID. Otherwise it&#39;s treated as a regular
</span><span id="__span-29-36"><a id="__codelineno-29-36" name="__codelineno-29-36" href="#__codelineno-29-36"></a>                        expression and matched against the context/stream name specified
</span><span id="__span-29-37"><a id="__codelineno-29-37" name="__codelineno-29-37" href="#__codelineno-29-37"></a>                        by the NVTX library. If the invocation count is a positive
</span><span id="__span-29-38"><a id="__codelineno-29-38" name="__codelineno-29-38" href="#__codelineno-29-38"></a>                        number, it&#39;s strictly matched against the invocation of
</span><span id="__span-29-39"><a id="__codelineno-29-39" name="__codelineno-29-39" href="#__codelineno-29-39"></a>                        the kernel. Otherwise it&#39;s treated as a regular expression.
</span><span id="__span-29-40"><a id="__codelineno-29-40" name="__codelineno-29-40" href="#__codelineno-29-40"></a>                        Example: --kernels &quot;1:foo:bar:2&quot; will profile any kernel
</span><span id="__span-29-41"><a id="__codelineno-29-41" name="__codelineno-29-41" href="#__codelineno-29-41"></a>                        whose name contains &quot;bar&quot; and is the 2nd instance on context
</span><span id="__span-29-42"><a id="__codelineno-29-42" name="__codelineno-29-42" href="#__codelineno-29-42"></a>                        1 and on stream named &quot;foo&quot;.
</span><span id="__span-29-43"><a id="__codelineno-29-43" name="__codelineno-29-43" href="#__codelineno-29-43"></a>
</span><span id="__span-29-44"><a id="__codelineno-29-44" name="__codelineno-29-44" href="#__codelineno-29-44"></a>  -m,  --metrics &lt;metric names&gt;
</span><span id="__span-29-45"><a id="__codelineno-29-45" name="__codelineno-29-45" href="#__codelineno-29-45"></a>                        Specify the metrics to be profiled on certain device(s).
</span><span id="__span-29-46"><a id="__codelineno-29-46" name="__codelineno-29-46" href="#__codelineno-29-46"></a>                        Multiple metric names separated by comma can be specified.
</span><span id="__span-29-47"><a id="__codelineno-29-47" name="__codelineno-29-47" href="#__codelineno-29-47"></a>                        Which device(s) are profiled is controlled by the &quot;--devices&quot;
</span><span id="__span-29-48"><a id="__codelineno-29-48" name="__codelineno-29-48" href="#__codelineno-29-48"></a>                        option. Otherwise metrics will be collected on all devices.
</span><span id="__span-29-49"><a id="__codelineno-29-49" name="__codelineno-29-49" href="#__codelineno-29-49"></a>                        For a list of available metrics, use &quot;--query-metrics&quot;.
</span><span id="__span-29-50"><a id="__codelineno-29-50" name="__codelineno-29-50" href="#__codelineno-29-50"></a>                        Use &quot;--metrics all&quot; to profile all metrics available for
</span><span id="__span-29-51"><a id="__codelineno-29-51" name="__codelineno-29-51" href="#__codelineno-29-51"></a>                        each device.
</span><span id="__span-29-52"><a id="__codelineno-29-52" name="__codelineno-29-52" href="#__codelineno-29-52"></a>                        Use &quot;--devices&quot; and &quot;--kernels&quot; to select a specific kernel
</span><span id="__span-29-53"><a id="__codelineno-29-53" name="__codelineno-29-53" href="#__codelineno-29-53"></a>                        invocation.
</span><span id="__span-29-54"><a id="__codelineno-29-54" name="__codelineno-29-54" href="#__codelineno-29-54"></a>                        Note: &quot;--metrics all&quot; does not include some metrics which
</span><span id="__span-29-55"><a id="__codelineno-29-55" name="__codelineno-29-55" href="#__codelineno-29-55"></a>                        are needed for Visual Profiler&#39;s source level analysis.
</span><span id="__span-29-56"><a id="__codelineno-29-56" name="__codelineno-29-56" href="#__codelineno-29-56"></a>                        For that, use &quot;--analysis-metrics&quot;.
</span><span id="__span-29-57"><a id="__codelineno-29-57" name="__codelineno-29-57" href="#__codelineno-29-57"></a>
</span><span id="__span-29-58"><a id="__codelineno-29-58" name="__codelineno-29-58" href="#__codelineno-29-58"></a> --pc-sampling-period &lt;period&gt;
</span><span id="__span-29-59"><a id="__codelineno-29-59" name="__codelineno-29-59" href="#__codelineno-29-59"></a>                        Specify PC Sampling period in cycles,  at which the sampling
</span><span id="__span-29-60"><a id="__codelineno-29-60" name="__codelineno-29-60" href="#__codelineno-29-60"></a>                        records will be dumped. Allowed values for the period are
</span><span id="__span-29-61"><a id="__codelineno-29-61" name="__codelineno-29-61" href="#__codelineno-29-61"></a>                        integers between 5 to 31 both inclusive.
</span><span id="__span-29-62"><a id="__codelineno-29-62" name="__codelineno-29-62" href="#__codelineno-29-62"></a>                        This will set the sampling period to (2^period) cycles
</span><span id="__span-29-63"><a id="__codelineno-29-63" name="__codelineno-29-63" href="#__codelineno-29-63"></a>                        Default value is a number between 5 and 12 based on the setup.
</span><span id="__span-29-64"><a id="__codelineno-29-64" name="__codelineno-29-64" href="#__codelineno-29-64"></a>                        Note: Only available for GM20X+.
</span><span id="__span-29-65"><a id="__codelineno-29-65" name="__codelineno-29-65" href="#__codelineno-29-65"></a>
</span><span id="__span-29-66"><a id="__codelineno-29-66" name="__codelineno-29-66" href="#__codelineno-29-66"></a> --print-api-summary
</span><span id="__span-29-67"><a id="__codelineno-29-67" name="__codelineno-29-67" href="#__codelineno-29-67"></a>                  Print a summary of CUDA runtime/driver API calls.
</span><span id="__span-29-68"><a id="__codelineno-29-68" name="__codelineno-29-68" href="#__codelineno-29-68"></a>
</span><span id="__span-29-69"><a id="__codelineno-29-69" name="__codelineno-29-69" href="#__codelineno-29-69"></a> --print-api-trace
</span><span id="__span-29-70"><a id="__codelineno-29-70" name="__codelineno-29-70" href="#__codelineno-29-70"></a>                  Print CUDA runtime/driver API trace.
</span><span id="__span-29-71"><a id="__codelineno-29-71" name="__codelineno-29-71" href="#__codelineno-29-71"></a>
</span><span id="__span-29-72"><a id="__codelineno-29-72" name="__codelineno-29-72" href="#__codelineno-29-72"></a> --print-gpu-trace
</span><span id="__span-29-73"><a id="__codelineno-29-73" name="__codelineno-29-73" href="#__codelineno-29-73"></a>                        Print individual kernel invocations (including CUDA memcpy&#39;s/memset&#39;s)
</span><span id="__span-29-74"><a id="__codelineno-29-74" name="__codelineno-29-74" href="#__codelineno-29-74"></a>                        and sort them in chronological order. In event/metric profiling
</span><span id="__span-29-75"><a id="__codelineno-29-75" name="__codelineno-29-75" href="#__codelineno-29-75"></a>                        mode, show events/metrics for each kernel invocation.
</span><span id="__span-29-76"><a id="__codelineno-29-76" name="__codelineno-29-76" href="#__codelineno-29-76"></a>  -s,  --print-summary
</span><span id="__span-29-77"><a id="__codelineno-29-77" name="__codelineno-29-77" href="#__codelineno-29-77"></a>                        Print a summary of the profiling result on screen. Note:
</span><span id="__span-29-78"><a id="__codelineno-29-78" name="__codelineno-29-78" href="#__codelineno-29-78"></a>                        This is the default unless &quot;--export-profile&quot; or other print
</span><span id="__span-29-79"><a id="__codelineno-29-79" name="__codelineno-29-79" href="#__codelineno-29-79"></a>                        options are used.
</span><span id="__span-29-80"><a id="__codelineno-29-80" name="__codelineno-29-80" href="#__codelineno-29-80"></a>
</span><span id="__span-29-81"><a id="__codelineno-29-81" name="__codelineno-29-81" href="#__codelineno-29-81"></a>  -o,  --export-profile &lt;filename&gt;
</span><span id="__span-29-82"><a id="__codelineno-29-82" name="__codelineno-29-82" href="#__codelineno-29-82"></a>                        Export the result file which can be imported later or opened
</span><span id="__span-29-83"><a id="__codelineno-29-83" name="__codelineno-29-83" href="#__codelineno-29-83"></a>                        by the NVIDIA Visual Profiler.
</span><span id="__span-29-84"><a id="__codelineno-29-84" name="__codelineno-29-84" href="#__codelineno-29-84"></a>                                &quot;%p&quot; in the file name string is replaced with the
</span><span id="__span-29-85"><a id="__codelineno-29-85" name="__codelineno-29-85" href="#__codelineno-29-85"></a>                        process ID of the application being profiled.
</span><span id="__span-29-86"><a id="__codelineno-29-86" name="__codelineno-29-86" href="#__codelineno-29-86"></a>                                &quot;%q{&lt;ENV&gt;}&quot; in the file name string is replaced
</span><span id="__span-29-87"><a id="__codelineno-29-87" name="__codelineno-29-87" href="#__codelineno-29-87"></a>                        with the value of the environment variable &quot;&lt;ENV&gt;&quot;. If the
</span><span id="__span-29-88"><a id="__codelineno-29-88" name="__codelineno-29-88" href="#__codelineno-29-88"></a>                        environment variable is not set it&#39;s an error.
</span><span id="__span-29-89"><a id="__codelineno-29-89" name="__codelineno-29-89" href="#__codelineno-29-89"></a>                                &quot;%h&quot; in the file name string is replaced with the
</span><span id="__span-29-90"><a id="__codelineno-29-90" name="__codelineno-29-90" href="#__codelineno-29-90"></a>                        hostname of the system.
</span><span id="__span-29-91"><a id="__codelineno-29-91" name="__codelineno-29-91" href="#__codelineno-29-91"></a>                                &quot;%%&quot; in the file name string is replaced with &quot;%&quot;.
</span><span id="__span-29-92"><a id="__codelineno-29-92" name="__codelineno-29-92" href="#__codelineno-29-92"></a>                                Any other character following &quot;%&quot; is illegal.
</span><span id="__span-29-93"><a id="__codelineno-29-93" name="__codelineno-29-93" href="#__codelineno-29-93"></a>                        By default, this option disables the summary output. Note:
</span><span id="__span-29-94"><a id="__codelineno-29-94" name="__codelineno-29-94" href="#__codelineno-29-94"></a>                        If the application being profiled creates child processes,
</span><span id="__span-29-95"><a id="__codelineno-29-95" name="__codelineno-29-95" href="#__codelineno-29-95"></a>                        or if &#39;--profile-all-processes&#39; is used, the &quot;%p&quot; format
</span><span id="__span-29-96"><a id="__codelineno-29-96" name="__codelineno-29-96" href="#__codelineno-29-96"></a>                        is needed to get correct export files for each process.
</span></code></pre></div>
<p>metric具体含义：<a href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html#metrics-reference">1. Preparing An Application For Profiling — Profiler 12.3 documentation (nvidia.com)</a></p>
<blockquote>
<p>The <a href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html#visual-profiler">Visual Profiler</a> is a graphical profiling tool that displays a timeline of your application’s CPU and GPU activity, and that includes an automated analysis engine to identify optimization opportunities. The <a href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html#nvprof">nvprof</a> profiling tool enables you to collect and view profiling data from the command-line.</p>
</blockquote>
<p>下一代</p>
<blockquote>
<p><strong>Note that Visual Profiler and nvprof will be deprecated in a future CUDA release.</strong> The NVIDIA Volta platform is the last architecture on which these tools are fully supported. It is recommended to use next-generation tools <a href="https://developer.nvidia.com/nsight-systems">NVIDIA Nsight Systems</a> for GPU and CPU sampling and tracing and <a href="https://developer.nvidia.com/nsight-compute">NVIDIA Nsight Compute</a> for GPU kernel profiling.</p>
</blockquote>
<p>迁移：<a href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html#migrating-to-nsight-tools-from-visual-profiler-and-nvprof">1. Preparing An Application For Profiling — Profiler 12.3 documentation (nvidia.com)</a></p>
<ul>
<li>An <strong>event</strong> is a countable activity, action, or occurrence on a device. It corresponds to a single hardware counter value which is collected during kernel execution. To see a list of all available events on a particular NVIDIA GPU, type <code>nvprof --query-events</code>.</li>
<li>A <strong>metric</strong> is a characteristic of an application that is calculated from one or more event values. To see a list of all available metrics on a particular NVIDIA GPU, type <code>nvprof --query-metrics</code>. You can also refer to the <a href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html#metrics-reference">metrics reference</a> .</li>
</ul>
<p>支持cudaProfilerStart, Stop CUDA API用于专注部分代码的分析。nvprof需要使用--profile-from-start off来使用</p>
<p>NVTX用于给CPU代码打上标记，好在工具里看到</p>
<blockquote>
<p>To understand what the application’s CPU threads are doing outside of CUDA function calls, you can use the <a href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html#nvidia-tools-extension">NVIDIA Tools Extension API</a> (NVTX). When you add NVTX markers and ranges to your application, the <a href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html#timeline-view">Timeline View</a> shows when your CPU threads are executing within those regions.</p>
</blockquote>
<p>The Visual Profiler is available as both a standalone application and as part of Nsight Eclipse Edition. The standalone version of the Visual Profiler, <code>nvvp</code>, is included in the CUDA Toolkit for all supported OSes</p>
<p>流程
- 准备应用程序
  - 二进制程序，不用专门修改。但是使用NVTX更好</p>
<h2 id="nsight-compute">Nsight Compute<a class="headerlink" href="#nsight-compute" title="Permanent link">&para;</a></h2>
<p><a href="https://docs.nvidia.com/nsight-compute/index.html">Nsight Compute Documentation (nvidia.com)</a>
- <a href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html">Kernel Profiling Guide</a>
    - Kernel Profiling Guide with metric types and meaning, data collection modes and FAQ for common problems.
- <a href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html">Nsight Compute</a>
    - NVIDIA Nsight Compute User Interface (UI) manual. Information on all views, controls and workflows within the tool UI. Transitions guide for Visual Profiler. 
- <a href="https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html">Nsight Compute CLI</a>
    - NVIDIA Nsight Compute Command Line Interface (CLI) manual. Information on workflows and options for the command line, including multi-process profiling and NVTX filtering. Transitions guide for Nvprof.</p>
<ul>
<li>nvprof：sm7.5 之前使用，被nsight compute替代</li>
<li>Nsight compute</li>
<li>图形化界面</li>
<li>命令行：ncu</li>
</ul>
<h3 id="ncu">ncu<a class="headerlink" href="#ncu" title="Permanent link">&para;</a></h3>
<p><a href="https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html">Nsight Compute CLI :: Nsight Compute Documentation (nvidia.com)</a></p>
<h4 id="metric">metric<a class="headerlink" href="#metric" title="Permanent link">&para;</a></h4>
<p>--metric</p>
<blockquote>
<p>Specify all metrics to be profiled, separated by comma. If no --section options are given, only the temporary section containing all metrics listed using this option is collected. If --section options are given in addition to --metrics, all metrics from those sections and from --metrics are collected.</p>
</blockquote>
<p>nvprof metric在ncu中的表示
<a href="https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html#nvprof-metric-comparison">Nsight Compute CLI :: Nsight Compute Documentation (nvidia.com)</a></p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-30-1"><a id="__codelineno-30-1" name="__codelineno-30-1" href="#__codelineno-30-1"></a>|inst_executed|smsp__inst_executed.sum|
</span></code></pre></div>
<h3 id="问题">问题<a class="headerlink" href="#问题" title="Permanent link">&para;</a></h3>
<h4 id="profiling-is-not-supported-on-this-device">Profiling is not supported on this device<a class="headerlink" href="#profiling-is-not-supported-on-this-device" title="Permanent link">&para;</a></h4>
<p>Nsight compute支持的GPU：<a href="https://docs.nvidia.com/nsight-compute/ReleaseNotes/index.html#gpu-support">Release Notes :: Nsight Compute Documentation (nvidia.com)</a>
- 不支持pascal（如gtx1080），从Volta GV100开始支持</p>
<p><img alt="" src="https://raw.githubusercontent.com/TheRainstorm/.image-bed/main/20230419195327.png" /></p>
<p><img alt="" src="https://raw.githubusercontent.com/TheRainstorm/.image-bed/main/20230419203147.png" /></p>
<h4 id="无权限使用metric">无权限使用metric<a class="headerlink" href="#无权限使用metric" title="Permanent link">&para;</a></h4>
<p>修改/etc/modprobe.d，重启保持修改
<div class="language-text highlight"><pre><span></span><code><span id="__span-31-1"><a id="__codelineno-31-1" name="__codelineno-31-1" href="#__codelineno-31-1"></a>sudo vim /etc/modprobe.d/nvidia_profile.conf
</span><span id="__span-31-2"><a id="__codelineno-31-2" name="__codelineno-31-2" href="#__codelineno-31-2"></a>
</span><span id="__span-31-3"><a id="__codelineno-31-3" name="__codelineno-31-3" href="#__codelineno-31-3"></a>options nvidia NVreg_RestrictProfilingToAdminUsers=0
</span><span id="__span-31-4"><a id="__codelineno-31-4" name="__codelineno-31-4" href="#__codelineno-31-4"></a>
</span><span id="__span-31-5"><a id="__codelineno-31-5" name="__codelineno-31-5" href="#__codelineno-31-5"></a>update-initramfs -u -k all #更新initramfs, -k all指定所有内核版本
</span></code></pre></div></p>
<p>不用重启，临时修改方法
<div class="language-text highlight"><pre><span></span><code><span id="__span-32-1"><a id="__codelineno-32-1" name="__codelineno-32-1" href="#__codelineno-32-1"></a>modprobe -rf nvidia_uvm nvidia_drm nvidia_modeset nvidia-vgpu-vfio nvidia
</span><span id="__span-32-2"><a id="__codelineno-32-2" name="__codelineno-32-2" href="#__codelineno-32-2"></a>
</span><span id="__span-32-3"><a id="__codelineno-32-3" name="__codelineno-32-3" href="#__codelineno-32-3"></a>modprobe nvidia NVreg_RestrictProfilingToAdminUsers=0
</span></code></pre></div></p>
<p>无法移除时，查看是什么进程占用了gpu
<div class="language-text highlight"><pre><span></span><code><span id="__span-33-1"><a id="__codelineno-33-1" name="__codelineno-33-1" href="#__codelineno-33-1"></a>sudo lsof /dev/nvidia*
</span></code></pre></div></p>
<p>可能需要停止nvidia-persistenced.service服务
<div class="language-text highlight"><pre><span></span><code><span id="__span-34-1"><a id="__codelineno-34-1" name="__codelineno-34-1" href="#__codelineno-34-1"></a>sudo systemctl status nvidia-persistenced.service
</span></code></pre></div></p>
<h2 id="调试工具">调试工具<a class="headerlink" href="#调试工具" title="Permanent link">&para;</a></h2>
<h3 id="cuda-memck">cuda-memck<a class="headerlink" href="#cuda-memck" title="Permanent link">&para;</a></h3>
<p>使用cuda-memcheck检查程序是否有非法地址访问。会使得程序执行变慢
<div class="language-text highlight"><pre><span></span><code><span id="__span-35-1"><a id="__codelineno-35-1" name="__codelineno-35-1" href="#__codelineno-35-1"></a>cuda-memcheck prog arg...
</span></code></pre></div></p>
<h3 id="cuda-gdb调试">cuda-gdb调试<a class="headerlink" href="#cuda-gdb调试" title="Permanent link">&para;</a></h3>
<div class="language-text highlight"><pre><span></span><code><span id="__span-36-1"><a id="__codelineno-36-1" name="__codelineno-36-1" href="#__codelineno-36-1"></a>nvcc -g -G XXX.cu -o XXX # -g对于cpu, -G对于GPU
</span></code></pre></div>
<p>cuda-gdb和gdb使用类似。</p>
<p>cuda程序如果代码写错，执行时只能从内核日志中看到报错信息（如Xid报错），非常不便。</p>
<p>而使用cuda-gdb可以直接定位哪出代码访存错误：
<div class="language-text highlight"><pre><span></span><code><span id="__span-37-1"><a id="__codelineno-37-1" name="__codelineno-37-1" href="#__codelineno-37-1"></a>(cuda-gdb) r 10 10 10                                                                                CUDA Exception: Warp Illegal Address                                                                 The exception was triggered at PC 0x55555617ff10 (GEMM.cu:82)
</span><span id="__span-37-2"><a id="__codelineno-37-2" name="__codelineno-37-2" href="#__codelineno-37-2"></a>
</span><span id="__span-37-3"><a id="__codelineno-37-3" name="__codelineno-37-3" href="#__codelineno-37-3"></a>Thread 1 &quot;GEMM&quot; received signal CUDA_EXCEPTION_14, Warp Illegal Address.
</span><span id="__span-37-4"><a id="__codelineno-37-4" name="__codelineno-37-4" href="#__codelineno-37-4"></a>[Switching focus to CUDA kernel 0, grid 4, block (0,0,0), thread (0,6,0), device 0, sm 0, warp 6, lane 0] 0x000055555617ff20 in gemm_block_shared&lt;32, 32, 8&gt;&lt;&lt;&lt;(32,32,1),(32,32,1)&gt;&gt;&gt; (A=0x7fffbda00000, B=0x7fffd7800000, C=0x7fffd7c00000, m=1024, k=1024, n=1024) at GEMM.cu:82
</span><span id="__span-37-5"><a id="__codelineno-37-5" name="__codelineno-37-5" href="#__codelineno-37-5"></a>82                  Bs[ty][tx] = B(iter * bm + ty, bx * bk + tx); //(tx, ty) in block B(iter, bx)
</span><span id="__span-37-6"><a id="__codelineno-37-6" name="__codelineno-37-6" href="#__codelineno-37-6"></a>(cuda-gdb) quit
</span><span id="__span-37-7"><a id="__codelineno-37-7" name="__codelineno-37-7" href="#__codelineno-37-7"></a>A debugging session is active.
</span><span id="__span-37-8"><a id="__codelineno-37-8" name="__codelineno-37-8" href="#__codelineno-37-8"></a>        Inferior 1 [process 32589] will be killed.
</span><span id="__span-37-9"><a id="__codelineno-37-9" name="__codelineno-37-9" href="#__codelineno-37-9"></a>Quit anyway? (y or n) y
</span></code></pre></div></p>
<h2 id="nvbit">NVbit<a class="headerlink" href="#nvbit" title="Permanent link">&para;</a></h2>
<p><div class="language-cpp highlight"><pre><span></span><code><span id="__span-38-1"><a id="__codelineno-38-1" name="__codelineno-38-1" href="#__codelineno-38-1"></a><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="nf">__ballot</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">predicate</span><span class="p">);</span><span class="w"> </span><span class="err">#</span>
</span></code></pre></div>
- If <code>predicate</code> is nonzero, <code>__ballot</code> returns a value with the <code>N</code>th bit set, where <code>N</code> is the thread index.</p>
<div class="language-csharp highlight"><pre><span></span><code><span id="__span-39-1"><a id="__codelineno-39-1" name="__codelineno-39-1" href="#__codelineno-39-1"></a><span class="kt">int</span><span class="w"> </span><span class="nf">atomicOr</span><span class="p">(</span><span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">address</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">val</span><span class="p">);</span>
</span></code></pre></div>
<h3 id="warp-level指令">warp-level指令<a class="headerlink" href="#warp-level指令" title="Permanent link">&para;</a></h3>
<p><a href="https://tschmidt23.github.io/cse599i/CSE%20599%20I%20Accelerated%20Computing%20-%20Programming%20GPUs%20Lecture%2018.pdf">CSE 599 I Accelerated Computing - Programming GPUs Lecture 18.pdf (tschmidt23.github.io)</a></p>
<p><img alt="" src="https://raw.githubusercontent.com/TheRainstorm/.image-bed/main/20230627162321.png" /></p>
<p><img alt="" src="https://raw.githubusercontent.com/TheRainstorm/.image-bed/main/20230627162434.png" /></p>
<p><img alt="" src="https://raw.githubusercontent.com/TheRainstorm/.image-bed/main/20230627163656.png" /></p>
<h2 id="cuda-sdk">cuda SDK<a class="headerlink" href="#cuda-sdk" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p>HPC SDK
<a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/nvhpc">NVIDIA HPC SDK | NVIDIA NGC</a>
<a href="https://docs.nvidia.com/hpc-sdk/hpc-sdk-release-notes/index.html">Release Notes Version 23.3 (nvidia.com)</a></p>
</li>
<li>
<p>HPC benchmark
<a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/hpc-benchmarks">NVIDIA HPC-Benchmarks | NVIDIA NGC</a></p>
</li>
</ul>







  
  




  



      
    </article>
  </div>

          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
      
        
      
      <nav class="md-footer__inner md-grid" aria-label="页脚" >
        
          
          <a href="../2023-04-16-CUDA%E6%9E%B6%E6%9E%84/" class="md-footer__link md-footer__link--prev" aria-label="上一页: CUDA架构">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                上一页
              </span>
              <div class="md-ellipsis">
                CUDA架构
              </div>
            </div>
          </a>
        
        
          
          <a href="../2023-04-16-CUDA%E4%BC%98%E5%8C%96/" class="md-footer__link md-footer__link--next" aria-label="下一页: CUDA优化">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                下一页
              </span>
              <div class="md-ellipsis">
                CUDA优化
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/TheRainstorm" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "../../../../..", "features": ["navigation.instant", "navigation.instant.progress", "navigation.tracking", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.footer", "content.code.copy", "toc.follow", "toc.integrate"], "search": "../../../../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../../../../assets/javascripts/bundle.d7c377c4.min.js"></script>
      
        <script src="../../../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>